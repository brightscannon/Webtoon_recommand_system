{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png','retina'}\n",
    "from IPython.display import clear_output # clear_output() 으로 아웃풋 제거 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10339734923390974575\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 1451553587\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 5049162139419150496\n",
      "physical_device_desc: \"device: 0, name: GeForce GTX 960, pci bus id: 0000:01:00.0, compute capability: 5.2\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  텐서플로우 튜토리얼 - 딥러닝 도구들1\n",
    "- 튜토리얼을 제공하는 깃헙https://github.com/golbin/TensorFlow-Tutorials\n",
    "- 모두를 위한 딥러닝 강의 https://www.youtube.com/watch?v=BS6O0zOGX4E&list=PLlMkM4tgfjnLSOjrEJN31gZATbcj_MpUm\n",
    "\n",
    "- 현재 나와있는 이미지 분석 기법들 정리한 블로그\n",
    "    - https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/\n",
    "\n",
    "\n",
    "## 목차\n",
    "- MNIST (손글씨 숫자 인식)\n",
    "- CNN (이미지처리)\n",
    "    - layers 패키지로 재구성 및 코드비교\n",
    "- Autoencoder (비지도학습)\n",
    "- GAN (비지도 학습 + 생성모델)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST\n",
    "- 머신러닝 학습의 Hello World 와 같은 MNIST(손글씨 숫자 인식) 문제를 신경망으로 풀어봅니다.\n",
    "- 과적합 방지 기법 중 하나인 Dropout 을 사용해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망 모델 구성중...\n",
      "학습 시작!\n",
      "Epoch: 0003 Avg. cost = 0.113\n",
      "Epoch: 0006 Avg. cost = 0.063\n",
      "Epoch: 0009 Avg. cost = 0.041\n",
      "Epoch: 0012 Avg. cost = 0.032\n",
      "Epoch: 0015 Avg. cost = 0.026\n",
      "Epoch: 0018 Avg. cost = 0.023\n",
      "Epoch: 0021 Avg. cost = 0.021\n",
      "Epoch: 0024 Avg. cost = 0.017\n",
      "Epoch: 0027 Avg. cost = 0.016\n",
      "Epoch: 0030 Avg. cost = 0.017\n",
      "\n",
      "최적화 완료!\n",
      "정확도: 0.9802\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsEAAAGfCAYAAAC+3Q9uAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvEMTDAAAAO/QBAMAAMA7/w9p3buPGWujjAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x269c90ce748>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 207,
       "width": 352
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "# 텐서플로우에 기본 내장된 mnist 모듈을 이용하여 데이터를 로드합니다.\n",
    "# 지정한 폴더에 MNIST 데이터가 없는 경우 자동으로 데이터를 다운로드합니다.\n",
    "# one_hot 옵션은 레이블을 동물 분류 예제에서 보았던 one_hot 방식의 데이터로 만들어줍니다.\n",
    "print(\"mnist예제 받는중\" ,end='\\r')\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "clear_output()\n",
    "print(\"신경망 모델 구성중...\")\n",
    "#########=====================\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "\n",
    "# 입력 값의 차원은 [배치크기, 특성값] 으로 되어 있습니다.\n",
    "# 손글씨 이미지는 28x28 픽셀로 이루어져 있고, 이를 784개의 특성값으로 정합니다.\n",
    "X = tf.placeholder(tf.float32, [None, 784])\n",
    "# 결과값은 0~9까지 값을 가짐\n",
    "Y = tf.placeholder(tf.float32, [None,10])\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32) # dropout에 사용\n",
    "\n",
    "# 신경망의 레이어는 다음처럼 구성합니다.\n",
    "# 784(입력 특성값)\n",
    "#   -> 256 (히든레이어 뉴런 갯수) -> 256 (히든레이어 뉴런 갯수)\n",
    "#   -> 10 (결과값 0~9 분류)\n",
    "\n",
    "W1 = tf.Variable(tf.random_normal([784, 256], stddev=0.01))\n",
    "# 입력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
    "L1 = tf.nn.relu(tf.matmul(X, W1))\n",
    "# 텐서플로우에 내장된 함수를 이용하여 dropout 을 적용합니다.\n",
    "# 함수에 적용할 레이어와 확률만 넣어주면 됩니다. 겁나 매직!!\n",
    "L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "W2 = tf.Variable(tf.random_normal([256, 256], stddev=0.01))\n",
    "# L1 레이어의 출력값에 가중치를 곱하고 ReLU 함수를 이용하여 레이어를 만듭니다.\n",
    "L2 = tf.nn.relu(tf.matmul(L1, W2))\n",
    "L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "W3 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "# 최종 모델의 출력값은 W3 변수를 곱해 10개의 분류를 가지게 됩니다.\n",
    "model = tf.matmul(L2, W3)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "\n",
    "print(\"학습 시작!\")\n",
    "\n",
    "#########======================\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(30):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        # 텐서플로우의 mnist 모델의 next_batch 함수를 이용해\n",
    "        # 지정한 크기만큼 학습할 데이터를 가져옵니다.\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost], feed_dict={X: batch_xs, Y: batch_ys,\n",
    "                                                            keep_prob:0.8})\n",
    "        total_cost += cost_val\n",
    "        \n",
    "    if (epoch+1) % 3 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "    else : \n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch), end='\\r')\n",
    "\n",
    "print('\\n최적화 완료!')\n",
    "\n",
    "#########===========================\n",
    "# 결과 확인\n",
    "######\n",
    "# model 로 예측한 값과 실제 레이블인 Y의 값을 비교합니다.\n",
    "# tf.argmax 함수를 이용해 예측한 값에서 가장 큰 값을 예측한 레이블이라고 평가합니다.\n",
    "# 예) [0.1 0 0 0.7 0 0.2 0 0 0 0] -> 3\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: mnist.test.images,\n",
    "                                   Y: mnist.test.labels,\n",
    "                                  keep_prob:1}))\n",
    "\n",
    "\n",
    "\n",
    "#########\n",
    "# 결과 확인 (matplot)\n",
    "######\n",
    "labels = sess.run(model,\n",
    "                  feed_dict={X: mnist.test.images,\n",
    "                             Y: mnist.test.labels,\n",
    "                             keep_prob: 1})\n",
    "\n",
    "fig = plt.figure()\n",
    "for i in range(10):\n",
    "    subplot = fig.add_subplot(2, 5, i + 1)\n",
    "    subplot.set_xticks([])\n",
    "    subplot.set_yticks([])\n",
    "    subplot.set_title('%d' % np.argmax(labels[i]))\n",
    "    subplot.imshow(mnist.test.images[i].reshape((28, 28)),\n",
    "                   cmap=plt.cm.gray_r)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN\n",
    "- 이미지 처리 분야에서 가장 유명한 신경망 모델인 CNN 을 이용하여 더 높은 인식률을 만들어봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습시작!델 구성중...\n",
      "Epoch: 0003 Avg. cost = 0.080\n",
      "Epoch: 0006 Avg. cost = 0.044\n",
      "Epoch: 0009 Avg. cost = 0.031\n",
      "Epoch: 0012 Avg. cost = 0.023\n",
      "Epoch: 0015 Avg. cost = 0.016\n",
      "\n",
      "최적화 완료!\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "print(\"mnist예제 받는중\" ,end='\\r')\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "clear_output()\n",
    "print(\"신경망 모델 구성중...\", end=\"\\r\")\n",
    "\n",
    "#########===============================\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "\n",
    "# 기존 모델에서는 입력 값을 28x28 하나의 차원으로 구성하였으나,\n",
    "# CNN 모델을 사용하기 위해 2차원 평면과 특성치의 형태를 갖는 구조로 만듭니다.\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# 각각의 변수와 레이어는 다음과 같은 형태로 구성됩니다.\n",
    "# W1 [3 3 1 32] -> [3 3]: 커널 크기, 1: 입력값 X 의 특성수, 32: 필터 갯수\n",
    "# L1 Conv shape=(?, 28, 28, 32)\n",
    "#    Pool     ->(?, 14, 14, 32)\n",
    "W1 = tf.Variable(tf.random_normal([3, 3, 1, 32], stddev=0.01))\n",
    "# tf.nn.conv2d 를 이용해 한칸씩 움직이는 컨볼루션 레이어를 쉽게 만들 수 있습니다.\n",
    "# padding='SAME' 은 커널 슬라이딩시 최외곽에서 한칸 밖으로 더 움직이는 옵션\n",
    "L1 = tf.nn.conv2d(X, W1, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L1 = tf.nn.relu(L1)\n",
    "# Pooling 역시 tf.nn.max_pool 을 이용하여 쉽게 구성할 수 있습니다.\n",
    "L1 = tf.nn.max_pool(L1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# L1 = tf.nn.dropout(L1, keep_prob)\n",
    "\n",
    "# L2 Conv shape=(?, 14, 14, 64)\n",
    "#    Pool     ->(?, 7, 7, 64)\n",
    "# W2 의 [3, 3, 32, 64] 에서 32 는 L1 에서 출력된 W1 의 마지막 차원, 필터의 크기 입니다.\n",
    "W2 = tf.Variable(tf.random_normal([3, 3, 32, 64], stddev=0.01))\n",
    "L2 = tf.nn.conv2d(L1, W2, strides=[1, 1, 1, 1], padding='SAME')\n",
    "L2 = tf.nn.relu(L2)\n",
    "L2 = tf.nn.max_pool(L2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')\n",
    "# L2 = tf.nn.dropout(L2, keep_prob)\n",
    "\n",
    "# FC 레이어: 입력값 7x7x64 -> 출력값 256\n",
    "# Full connect를 위해 직전의 Pool 사이즈인 (?, 7, 7, 64) 를 참고하여 차원을 줄여줍니다.\n",
    "#    Reshape  ->(?, 256)\n",
    "W3 = tf.Variable(tf.random_normal([7 * 7 * 64, 256], stddev=0.01))\n",
    "L3 = tf.reshape(L2, [-1, 7 * 7 * 64])\n",
    "L3 = tf.matmul(L3, W3)\n",
    "L3 = tf.nn.relu(L3)\n",
    "L3 = tf.nn.dropout(L3, keep_prob)\n",
    "\n",
    "# 최종 출력값 L3 에서의 출력 256개를 입력값으로 받아서 0~9 레이블인 10개의 출력값을 만듭니다.\n",
    "W4 = tf.Variable(tf.random_normal([256, 10], stddev=0.01))\n",
    "model = tf.matmul(L3, W4)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "# 최적화 함수를 RMSPropOptimizer 로 바꿔서 결과를 확인해봅시다.\n",
    "# optimizer = tf.train.RMSPropOptimizer(0.001, 0.9).minimize(cost)\n",
    "print(\"학습시작!\")\n",
    "\n",
    "#########================================\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples / batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # 이미지 데이터를 CNN 모델을 위한 자료형태인 [28 28 1] 의 형태로 재구성합니다.\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          keep_prob: 0.7})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    if (epoch+1) % 3 == 0:\n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "    else : \n",
    "        print('Epoch:', '%04d' % (epoch + 1),\n",
    "              'Avg. cost =', '{:.3f}'.format(total_cost / total_batch), end='\\r')\n",
    "\n",
    "print('\\n최적화 완료!')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tensorflow.layers를 사용하여 더 쉽고 보기좋게 만들어보자\n",
    "- 신경망 구성을 손쉽게 해 주는 유틸리티 모음인 tensorflow.layers 를 사용해봅니다.\n",
    "- 위의 코드를 재구성한 것이니, 소스를 한 번 비교해보세요.\n",
    "- 이처럼 TensorFlow 에는 간단하게 사용할 수 있는 다양한 함수와 유틸리티들이 매우 많이 마련되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, 28, 28, 1])\n",
    "Y = tf.placeholder(tf.float32, [None, 10])\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "# 기본적으로 inputs, outputs size, kernel_size 만 넣어주면\n",
    "# 활성화 함수 적용은 물론, 컨볼루션 신경망을 만들기 위한 나머지 수치들은 알아서 계산해줍니다.\n",
    "# 특히 Weights 를 계산하는데 xavier_initializer 를 쓰고 있는 등,\n",
    "# 크게 신경쓰지 않아도 일반적으로 효율적인 신경망을 만들어줍니다.\n",
    "L1 = tf.layers.conv2d(X, 32, [3, 3], activation=tf.nn.relu)\n",
    "L1 = tf.layers.max_pooling2d(L1, [2, 2], [2, 2])\n",
    "L1 = tf.layers.dropout(L1, 0.7, is_training)\n",
    "\n",
    "L2 = tf.layers.conv2d(L1, 64, [3, 3], activation=tf.nn.relu)\n",
    "L2 = tf.layers.max_pooling2d(L2, [2, 2], [2, 2])\n",
    "L2 = tf.layers.dropout(L2, 0.7, is_training)\n",
    "\n",
    "L3 = tf.contrib.layers.flatten(L2)\n",
    "L3 = tf.layers.dense(L3, 256, activation=tf.nn.relu)\n",
    "L3 = tf.layers.dropout(L3, 0.5, is_training)\n",
    "\n",
    "model = tf.layers.dense(L3, 10, activation=None)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(0.001).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "batch_size = 100\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(15):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        batch_xs = batch_xs.reshape(-1, 28, 28, 1)\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs,\n",
    "                                          Y: batch_ys,\n",
    "                                          is_training: True})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.4f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "######\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                        feed_dict={X: mnist.test.images.reshape(-1, 28, 28, 1),\n",
    "                                   Y: mnist.test.labels,\n",
    "                                   is_training: False}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autoencoder - 비지도학습\n",
    "- 대표적인 비지도(Unsupervised) 학습 방법인 Autoencoder 를 구현해봅니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Avg. cost = 0.2004\n",
      "Epoch: 0002 Avg. cost = 0.0626\n",
      "Epoch: 0003 Avg. cost = 0.0520\n",
      "Epoch: 0004 Avg. cost = 0.0456\n",
      "Epoch: 0005 Avg. cost = 0.0417\n",
      "Epoch: 0006 Avg. cost = 0.0395\n",
      "Epoch: 0007 Avg. cost = 0.0372\n",
      "Epoch: 0008 Avg. cost = 0.0352\n",
      "Epoch: 0009 Avg. cost = 0.0343\n",
      "Epoch: 0010 Avg. cost = 0.0337\n",
      "Epoch: 0011 Avg. cost = 0.0334\n",
      "Epoch: 0012 Avg. cost = 0.0331\n",
      "Epoch: 0013 Avg. cost = 0.0327\n",
      "Epoch: 0014 Avg. cost = 0.0326\n",
      "Epoch: 0015 Avg. cost = 0.0324\n",
      "Epoch: 0016 Avg. cost = 0.0323\n",
      "Epoch: 0017 Avg. cost = 0.0322\n",
      "Epoch: 0018 Avg. cost = 0.0320\n",
      "Epoch: 0019 Avg. cost = 0.0316\n",
      "Epoch: 0020 Avg. cost = 0.0310\n",
      "최적화 완료!\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAAEYCAYAAADyAFe2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHwQ6TXHg2kpqAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16d8b52ee80>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 140,
       "width": 591
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "learning_rate = 0.01\n",
    "training_epoch = 20\n",
    "batch_size = 100\n",
    "# 신경망 레이어 구성 옵션\n",
    "n_hidden = 256  # 히든 레이어의 뉴런 갯수\n",
    "n_input = 28*28   # 입력값 크기 - 이미지 픽셀수\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "# Y 가 없습니다. 입력값을 Y로 사용하기 때문입니다.\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "\n",
    "# 인코더 레이어와 디코더 레이어의 가중치와 편향 변수를 설정합니다.\n",
    "# 다음과 같이 이어지는 레이어를 구성하기 위한 값들 입니다.\n",
    "# input -> encode -> decode -> output\n",
    "W_encode = tf.Variable(tf.random_normal([n_input, n_hidden]))\n",
    "b_encode = tf.Variable(tf.random_normal([n_hidden]))\n",
    "# sigmoid 함수를 이용해 신경망 레이어를 구성합니다.\n",
    "# sigmoid(X * W + b)\n",
    "# 인코더 레이어 구성\n",
    "encoder = tf.nn.sigmoid(\n",
    "                tf.add(tf.matmul(X, W_encode), b_encode))\n",
    "\n",
    "# encode 의 아웃풋 크기를 입력값보다 작은 크기로 만들어 정보를 압축하여 특성을 뽑아내고,\n",
    "# decode 의 출력을 입력값과 동일한 크기를 갖도록하여 입력과 똑같은 아웃풋을 만들어 내도록 합니다.\n",
    "# 히든 레이어의 구성과 특성치을 뽑아내는 알고리즘을 변경하여 다양한 오토인코더를 만들 수 있습니다.\n",
    "W_decode = tf.Variable(tf.random_normal([n_hidden, n_input]))\n",
    "b_decode = tf.Variable(tf.random_normal([n_input]))\n",
    "# 디코더 레이어 구성\n",
    "# 이 디코더가 최종 모델이 됩니다.\n",
    "decoder = tf.nn.sigmoid(\n",
    "                tf.add(tf.matmul(encoder, W_decode), b_decode))\n",
    "\n",
    "# 디코더는 인풋과 최대한 같은 결과를 내야 하므로, 디코딩한 결과를 평가하기 위해\n",
    "# 입력 값인 X 값을 평가를 위한 실측 결과 값으로하여 decoder 와의 차이를 손실값으로 설정합니다.\n",
    "cost = tf.reduce_mean(tf.pow(X - decoder, 2))\n",
    "optimizer = tf.train.RMSPropOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(training_epoch):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.4f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "# 입력값(위쪽)과 모델이 생성한 값(아래쪽)을 시각적으로 비교해봅니다.\n",
    "######\n",
    "sample_size = 10\n",
    "\n",
    "samples = sess.run(decoder,\n",
    "                   feed_dict={X: mnist.test.images[:sample_size]})\n",
    "\n",
    "fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "for i in range(sample_size):\n",
    "    ax[0][i].set_axis_off()\n",
    "    ax[1][i].set_axis_off()\n",
    "    ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "    ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GAN\n",
    "- 2016년에 가장 관심을 많이 받았던 비감독(Unsupervised) 학습 방법인\n",
    "- Generative Adversarial Network(GAN)을 구현해봅니다.\n",
    "- https://arxiv.org/abs/1406.2661"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "print(\"트레이닝 셋 로드중...\")\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "clear_output()\n",
    "print(\"트레이닝 셋 로드 완료!\")\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "total_epoch = 200\n",
    "batch_size = 100\n",
    "learning_rate = 0.0002\n",
    "# 신경망 레이어 구성 옵션\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128 #생성기의 입력값으로 사용할 노이즈의 크기\n",
    "print(\"모델구성중...\",end=\"\\r\")\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "# GAN도 Unsupervised 학습이므로 Autoencoder 처럼 Y를 사용하지 않는다.\n",
    "X = tf.placeholder(tf.float32,[None, n_input])\n",
    "# 노이즈 Z를 입력값으로 사용\n",
    "Z = tf.placeholder(tf.float32,[None, n_noise])\n",
    "\n",
    "# 생성기 신경망에 사용하는 변수들\n",
    "G_W1 = tf.Variable(tf.random_normal([n_noise, n_hidden], stddev=0.01))\n",
    "G_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "G_W2 = tf.Variable(tf.random_normal([n_hidden, n_input], stddev=0.01))\n",
    "G_b2 = tf.Variable(tf.zeros([n_input]))\n",
    "\n",
    "# 판별기 신경망에 사용하는 변수들\n",
    "D_W1 = tf.Variable(tf.random_normal([n_input, n_hidden], stddev=0.01))\n",
    "D_b1 = tf.Variable(tf.zeros([n_hidden]))\n",
    "# 판별기의 최종 결과값은 얼마나 진짜와 가깝냐를 판단하는 한 개의 스칼라값임\n",
    "D_W2 = tf.Variable(tf.random_normal([n_hidden, 1], stddev=0.01))\n",
    "D_b2 = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "\n",
    "###\n",
    "# 신경망 구성\n",
    "\n",
    "print(\"신경망 구성중...\",end=\"\\r\")\n",
    "\n",
    "# 생성기(G) 신경망을 구성합니다.\n",
    "def generator(noise_z):\n",
    "    hidden = tf.nn.relu(tf.matmul(noise_z, G_W1) + G_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden,G_W2) + G_b2)\n",
    "    return output\n",
    "\n",
    "# 판별기(D) 신경망을 구성합니다.\n",
    "def discriminator(inputs):\n",
    "    hidden = tf.nn.relu(tf.matmul(inputs, D_W1) + D_b1)\n",
    "    output = tf.nn.sigmoid(tf.matmul(hidden, D_W2) + D_b2)\n",
    "    return output\n",
    "\n",
    "# 랜덤한 노이즈(Z)를 만듭니다.\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.normal(size=(batch_size, n_noise))\n",
    "\n",
    "# 노이즈를 이용해 랜덤한 이미지를 생성합니다.\n",
    "G = generator(Z)\n",
    "# 노이즈를 이용해 생성한 이미지가 진자 이미지인지 구합니다.\n",
    "D_gene = discriminator(G)\n",
    "# 진짜 이미지를 이용해 판별한 값을 구합니다.\n",
    "D_real = discriminator(X)\n",
    "\n",
    "# 논문에 따르면, GAN 모델의 최적화는 loss_G 와 loss_D 를 최대화 하는 것 입니다.\n",
    "# 다만 loss_D와 loss_G는 서로 연관관계가 있기 때문에 두 개의 손실값이 항상 같이 증가하는 경향을 보이지는 않을 것 입니다.\n",
    "# loss_D가 증가하려면 loss_G는 하락해야하고, loss_G가 증가하려면 loss_D는 하락해야하는 경쟁관계에 있기 때문입니다.\n",
    "# 논문의 수식에 따른 다음 로직을 보면 loss_D 를 최대화하기 위해서는 D_gene 값을 최소화하게 됩니다.\n",
    "# 판별기에 진짜 이미지를 넣었을 때에도 최대값을 : tf.log(D_real)\n",
    "# 가짜 이미지를 넣었을 때에도 최대값을 : tf.log(1 - D_gene)\n",
    "# 갖도록 학습시키기 때문입니다.\n",
    "# 이것은 판별기는 생성기가 만들어낸 이미지가 가짜라고 판단하도록 판별기 신경망을 학습시킵니다.\n",
    "loss_D = tf.reduce_mean(tf.log(D_real) + tf.log(1-D_gene))\n",
    "# 반면 loss_G 를 최대화하기 위해서는 D_gene 값을 최대화하게 되는데,\n",
    "# 이것은 가짜 이미지를 넣었을 때, 판별기가 최대한 실제 이미지라고 판단하도록 생성기 신경망을 학습시킵니다.\n",
    "# 논문에서는 loss_D 와 같은 수식으로 최소화 하는 생성기를 찾지만,\n",
    "# 결국 D_gene 값을 최대화하는 것이므로 다음과 같이 사용할 수 있습니다.\n",
    "loss_G = tf.reduce_mean(tf.log(D_gene))\n",
    "\n",
    "# loss_D 를 구할때는 판별기 신경망에 사용되는 변수만 사용하고,\n",
    "# loss_G 를 구할때는 생성기 신경망에 사용되는 변수만 사용하여 최적화한다\n",
    "D_var_list = [D_W1, D_b1, D_W2, D_b2]\n",
    "G_var_list = [G_W1, G_b1, G_W2, G_b2]\n",
    "\n",
    "# GAN 논문의 수식에 따르면 loss 를 극대화 해야하지만, minimize 하는 최적화 함수를 사용하기 때문에\n",
    "# 최적화 하려는 loss_D 와 loss_G 에 음수 부호를 붙여줍니다.\n",
    "train_D = tf.train.AdamOptimizer(learning_rate).minimize(-loss_D, var_list=D_var_list)\n",
    "train_G = tf.train.AdamOptimizer(learning_rate).minimize(-loss_G, var_list=G_var_list)\n",
    "\n",
    "\n",
    "print(\"신경망 모델 학습중...\")\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    print('running epoch ',epoch,'...',end=\"\\r\")\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "        \n",
    "        # 판별기와 생성기 신경망을 각각 학습시킨다.\n",
    "        _, loss_val_D = sess.run([train_D, loss_D], feed_dict = {X:batch_xs, Z:noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G], feed_dict = {Z:noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch, 'D loss{:.4}'.format(loss_val_D), 'G loss{:4}'.format(loss_val_G))\n",
    "    \n",
    "    #########\n",
    "    # 학습이 되어가는 모습을 보기 위해 주기적으로 이미지를 생성하여 저장\n",
    "    ######\n",
    "    \n",
    "    if epoch ==0 or (epoch + 1) % 5 == 0:\n",
    "        print(\"generate sample image...\",end=\"\")\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G, feed_dict={Z:noise})\n",
    "        \n",
    "        fig, ax = plt.subplots(1,sample_size, figsize=(sample_size,1))\n",
    "        \n",
    "        for i in range(sample_size):\n",
    "            ax[i].set_axis_off()\n",
    "            ax[i].imshow(np.reshape(samples[i], (28,28)))\n",
    "            \n",
    "        plt.savefig('samples/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(\"OK!\")\n",
    "        \n",
    "print('최적화 완료!')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- GAN 모델을 이용해 단순히 랜덤한 숫자를 생성하는 아닌,\n",
    "- 원하는 손글씨 숫자를 생성하는 모델을 만들어봅니다.\n",
    "- 이런 방식으로 흑백 사진을 컬러로 만든다든가, 또는 선화를 채색한다든가 하는 응용이 가능합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "신경망 모델 학습중...\n",
      "Epoch: 0000 D loss: 0.004045 G loss: 7.797\n",
      "generate sample image...OK!\n",
      "Epoch: 0001 D loss: 0.008677 G loss: 7.608\n",
      "Epoch: 0002 D loss: 0.01616 G loss: 9.926\n",
      "Epoch: 0003 D loss: 0.005243 G loss: 7.221\n",
      "Epoch: 0004 D loss: 0.008152 G loss: 10.44\n",
      "generate sample image...OK!\n",
      "Epoch: 0005 D loss: 0.00963 G loss: 8.993\n",
      "Epoch: 0006 D loss: 0.01436 G loss: 8.195\n",
      "Epoch: 0007 D loss: 0.07013 G loss: 8.625\n",
      "Epoch: 0008 D loss: 0.04842 G loss: 8.298\n",
      "Epoch: 0009 D loss: 0.1047 G loss: 6.567\n",
      "generate sample image...OK!\n",
      "Epoch: 0010 D loss: 0.1455 G loss: 7.724\n",
      "Epoch: 0011 D loss: 0.2922 G loss: 4.134\n",
      "Epoch: 0012 D loss: 0.3704 G loss: 4.554\n",
      "Epoch: 0013 D loss: 0.5018 G loss: 5.304\n",
      "Epoch: 0014 D loss: 0.2988 G loss: 4.155\n",
      "generate sample image...OK!\n",
      "Epoch: 0015 D loss: 0.3999 G loss: 3.6\n",
      "Epoch: 0016 D loss: 0.3165 G loss: 4.792\n",
      "Epoch: 0017 D loss: 0.3583 G loss: 4.309\n",
      "Epoch: 0018 D loss: 0.7157 G loss: 2.66\n",
      "Epoch: 0019 D loss: 0.7274 G loss: 2.348\n",
      "generate sample image...OK!\n",
      "Epoch: 0020 D loss: 0.5204 G loss: 3.535\n",
      "Epoch: 0021 D loss: 0.6707 G loss: 3.406\n",
      "Epoch: 0022 D loss: 0.4904 G loss: 3.374\n",
      "Epoch: 0023 D loss: 0.5119 G loss: 3.26\n",
      "Epoch: 0024 D loss: 0.6475 G loss: 2.752\n",
      "generate sample image...OK!\n",
      "Epoch: 0025 D loss: 0.7457 G loss: 2.487\n",
      "Epoch: 0026 D loss: 0.6981 G loss: 2.275\n",
      "Epoch: 0027 D loss: 0.3887 G loss: 3.375\n",
      "Epoch: 0028 D loss: 0.6175 G loss: 2.291\n",
      "Epoch: 0029 D loss: 0.3955 G loss: 2.829\n",
      "generate sample image...OK!\n",
      "Epoch: 0030 D loss: 0.5542 G loss: 2.656\n",
      "Epoch: 0031 D loss: 0.5842 G loss: 2.618\n",
      "Epoch: 0032 D loss: 0.6676 G loss: 2.763\n",
      "Epoch: 0033 D loss: 0.7303 G loss: 2.288\n",
      "Epoch: 0034 D loss: 0.7998 G loss: 1.985\n",
      "generate sample image...OK!\n",
      "Epoch: 0035 D loss: 0.7205 G loss: 2.574\n",
      "Epoch: 0036 D loss: 0.6631 G loss: 2.083\n",
      "Epoch: 0037 D loss: 0.789 G loss: 2.161\n",
      "Epoch: 0038 D loss: 0.6966 G loss: 2.377\n",
      "Epoch: 0039 D loss: 0.8241 G loss: 1.928\n",
      "generate sample image...OK!\n",
      "Epoch: 0040 D loss: 0.7395 G loss: 2.185\n",
      "Epoch: 0041 D loss: 0.7411 G loss: 2.267\n",
      "Epoch: 0042 D loss: 0.7982 G loss: 2.195\n",
      "Epoch: 0043 D loss: 0.7721 G loss: 2.218\n",
      "Epoch: 0044 D loss: 0.6777 G loss: 2.186\n",
      "generate sample image...OK!\n",
      "Epoch: 0045 D loss: 0.7235 G loss: 2.394\n",
      "Epoch: 0046 D loss: 0.7723 G loss: 2.277\n",
      "Epoch: 0047 D loss: 0.5658 G loss: 2.495\n",
      "Epoch: 0048 D loss: 0.6816 G loss: 2.168\n",
      "Epoch: 0049 D loss: 0.8086 G loss: 1.954\n",
      "generate sample image...OK!\n",
      "Epoch: 0050 D loss: 0.6387 G loss: 2.43\n",
      "Epoch: 0051 D loss: 0.75 G loss: 2.074\n",
      "Epoch: 0052 D loss: 0.9543 G loss: 2.081\n",
      "Epoch: 0053 D loss: 0.6078 G loss: 2.278\n",
      "Epoch: 0054 D loss: 0.5578 G loss: 2.766\n",
      "generate sample image...OK!\n",
      "Epoch: 0055 D loss: 0.7135 G loss: 2.274\n",
      "Epoch: 0056 D loss: 0.689 G loss: 2.056\n",
      "Epoch: 0057 D loss: 0.594 G loss: 2.315\n",
      "Epoch: 0058 D loss: 0.8223 G loss: 2.224\n",
      "Epoch: 0059 D loss: 0.6948 G loss: 2.229\n",
      "generate sample image...OK!\n",
      "Epoch: 0060 D loss: 0.7729 G loss: 2.163\n",
      "Epoch: 0061 D loss: 0.7616 G loss: 2.216\n",
      "Epoch: 0062 D loss: 0.7246 G loss: 2.368\n",
      "Epoch: 0063 D loss: 0.788 G loss: 2.282\n",
      "Epoch: 0064 D loss: 0.777 G loss: 2.299\n",
      "generate sample image...OK!\n",
      "Epoch: 0065 D loss: 0.797 G loss: 2.409\n",
      "Epoch: 0066 D loss: 0.6392 G loss: 2.187\n",
      "Epoch: 0067 D loss: 0.5728 G loss: 1.942\n",
      "Epoch: 0068 D loss: 0.6973 G loss: 1.851\n",
      "Epoch: 0069 D loss: 0.8099 G loss: 1.837\n",
      "generate sample image...OK!\n",
      "Epoch: 0070 D loss: 0.6694 G loss: 2.483\n",
      "Epoch: 0071 D loss: 0.5936 G loss: 2.161\n",
      "Epoch: 0072 D loss: 0.8042 G loss: 2.052\n",
      "Epoch: 0073 D loss: 0.7511 G loss: 1.989\n",
      "Epoch: 0074 D loss: 0.7407 G loss: 2.067\n",
      "generate sample image...OK!\n",
      "Epoch: 0075 D loss: 0.9662 G loss: 2.064\n",
      "Epoch: 0076 D loss: 0.7252 G loss: 2.129\n",
      "Epoch: 0077 D loss: 0.7198 G loss: 2.154\n",
      "Epoch: 0078 D loss: 0.6756 G loss: 2.054\n",
      "Epoch: 0079 D loss: 0.5963 G loss: 2.34\n",
      "generate sample image...OK!\n",
      "Epoch: 0080 D loss: 0.5849 G loss: 2.325\n",
      "Epoch: 0081 D loss: 0.8437 G loss: 2.201\n",
      "Epoch: 0082 D loss: 0.7277 G loss: 1.879\n",
      "Epoch: 0083 D loss: 0.7527 G loss: 2.444\n",
      "Epoch: 0084 D loss: 0.6704 G loss: 1.681\n",
      "generate sample image...OK!\n",
      "Epoch: 0085 D loss: 0.6354 G loss: 2.105\n",
      "Epoch: 0086 D loss: 0.8521 G loss: 1.745\n",
      "Epoch: 0087 D loss: 0.7918 G loss: 2.272\n",
      "Epoch: 0088 D loss: 0.7914 G loss: 1.868\n",
      "Epoch: 0089 D loss: 0.7478 G loss: 1.996\n",
      "generate sample image...OK!\n",
      "Epoch: 0090 D loss: 0.6455 G loss: 1.771\n",
      "Epoch: 0091 D loss: 0.6892 G loss: 2.194\n",
      "Epoch: 0092 D loss: 0.6175 G loss: 2.065\n",
      "Epoch: 0093 D loss: 0.7625 G loss: 2.349\n",
      "Epoch: 0094 D loss: 0.5485 G loss: 2.377\n",
      "generate sample image...OK!\n",
      "Epoch: 0095 D loss: 0.6257 G loss: 2.047\n",
      "Epoch: 0096 D loss: 0.6931 G loss: 2.507\n",
      "Epoch: 0097 D loss: 0.7567 G loss: 2.011\n",
      "Epoch: 0098 D loss: 0.7992 G loss: 1.688\n",
      "Epoch: 0099 D loss: 0.7442 G loss: 1.975\n",
      "generate sample image...OK!\n",
      "Epoch: 0100 D loss: 0.8188 G loss: 2.125\n",
      "Epoch: 0101 D loss: 0.664 G loss: 2.03\n",
      "Epoch: 0102 D loss: 0.8383 G loss: 2.103\n",
      "Epoch: 0103 D loss: 0.6896 G loss: 1.917\n",
      "Epoch: 0104 D loss: 0.7864 G loss: 1.831\n",
      "generate sample image...OK!\n",
      "Epoch: 0105 D loss: 0.6878 G loss: 2.149\n",
      "Epoch: 0106 D loss: 0.651 G loss: 2.324\n",
      "Epoch: 0107 D loss: 0.8241 G loss: 1.998\n",
      "Epoch: 0108 D loss: 0.7548 G loss: 1.783\n",
      "Epoch: 0109 D loss: 0.7602 G loss: 2.042\n",
      "generate sample image...OK!\n",
      "Epoch: 0110 D loss: 0.779 G loss: 2.238\n",
      "Epoch: 0111 D loss: 0.6855 G loss: 1.897\n",
      "Epoch: 0112 D loss: 0.6858 G loss: 2.31\n",
      "Epoch: 0113 D loss: 0.6769 G loss: 1.99\n",
      "Epoch: 0114 D loss: 0.7625 G loss: 1.712\n",
      "generate sample image...OK!\n",
      "Epoch: 0115 D loss: 0.6737 G loss: 2.09\n",
      "Epoch: 0116 D loss: 0.6363 G loss: 2.156\n",
      "Epoch: 0117 D loss: 0.7674 G loss: 1.927\n",
      "Epoch: 0118 D loss: 0.8433 G loss: 2.091\n",
      "Epoch: 0119 D loss: 0.7167 G loss: 2.14\n",
      "generate sample image...OK!\n",
      "Epoch: 0120 D loss: 0.6245 G loss: 2.191\n",
      "Epoch: 0121 D loss: 0.6933 G loss: 2.369\n",
      "Epoch: 0122 D loss: 0.9319 G loss: 1.788\n",
      "Epoch: 0123 D loss: 0.7541 G loss: 1.993\n",
      "Epoch: 0124 D loss: 0.6849 G loss: 2.048\n",
      "generate sample image...OK!\n",
      "Epoch: 0125 D loss: 0.753 G loss: 1.803\n",
      "Epoch: 0126 D loss: 0.8354 G loss: 1.74\n",
      "Epoch: 0127 D loss: 0.7109 G loss: 1.967\n",
      "Epoch: 0128 D loss: 0.6917 G loss: 2.305\n",
      "Epoch: 0129 D loss: 0.7932 G loss: 1.98\n",
      "generate sample image...OK!\n",
      "Epoch: 0130 D loss: 0.7823 G loss: 2.236\n",
      "Epoch: 0131 D loss: 0.6313 G loss: 2.332\n",
      "Epoch: 0132 D loss: 0.5781 G loss: 2.059\n",
      "Epoch: 0133 D loss: 0.7634 G loss: 1.646\n",
      "Epoch: 0134 D loss: 0.6684 G loss: 2.039\n",
      "generate sample image...OK!\n",
      "Epoch: 0135 D loss: 0.6985 G loss: 2.1\n",
      "Epoch: 0136 D loss: 0.7213 G loss: 1.954\n",
      "Epoch: 0137 D loss: 0.6814 G loss: 2.146\n",
      "Epoch: 0138 D loss: 0.674 G loss: 1.988\n",
      "Epoch: 0139 D loss: 0.6881 G loss: 2.366\n",
      "generate sample image...OK!\n",
      "Epoch: 0140 D loss: 0.5803 G loss: 2.336\n",
      "Epoch: 0141 D loss: 0.9163 G loss: 2.456\n",
      "Epoch: 0142 D loss: 0.796 G loss: 2.258\n",
      "Epoch: 0143 D loss: 0.6397 G loss: 1.975\n",
      "Epoch: 0144 D loss: 0.79 G loss: 2.19\n",
      "generate sample image...OK!\n",
      "Epoch: 0145 D loss: 0.7205 G loss: 1.92\n",
      "Epoch: 0146 D loss: 0.809 G loss: 2.083\n",
      "Epoch: 0147 D loss: 0.8682 G loss: 2.147\n",
      "Epoch: 0148 D loss: 0.7175 G loss: 2.286\n",
      "Epoch: 0149 D loss: 0.7456 G loss: 2.107\n",
      "generate sample image...OK!\n",
      "Epoch: 0150 D loss: 0.6537 G loss: 2.132\n",
      "Epoch: 0151 D loss: 0.6666 G loss: 1.934\n",
      "Epoch: 0152 D loss: 0.6065 G loss: 2.215\n",
      "Epoch: 0153 D loss: 0.9022 G loss: 2.091\n",
      "Epoch: 0154 D loss: 0.7534 G loss: 2.287\n",
      "generate sample image...OK!\n",
      "Epoch: 0155 D loss: 0.6712 G loss: 2.244\n",
      "Epoch: 0156 D loss: 0.7886 G loss: 2.477\n",
      "Epoch: 0157 D loss: 0.7153 G loss: 2.213\n",
      "Epoch: 0158 D loss: 0.6787 G loss: 1.989\n",
      "Epoch: 0159 D loss: 0.7097 G loss: 1.958\n",
      "generate sample image...OK!\n",
      "Epoch: 0160 D loss: 0.6713 G loss: 2.074\n",
      "Epoch: 0161 D loss: 0.5867 G loss: 2.431\n",
      "Epoch: 0162 D loss: 0.6508 G loss: 2.134\n",
      "Epoch: 0163 D loss: 0.7864 G loss: 2.058\n",
      "Epoch: 0164 D loss: 0.6837 G loss: 1.898\n",
      "generate sample image...OK!\n",
      "Epoch: 0165 D loss: 0.5916 G loss: 2.448\n",
      "Epoch: 0166 D loss: 0.7224 G loss: 1.983\n",
      "Epoch: 0167 D loss: 0.7283 G loss: 2.076\n",
      "running epoch  168 ...\r"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "clear_output()\n",
    "print(\"신경망 구성중...\",end=\"\\r\")\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "total_epoch = 200\n",
    "batch_size = 100\n",
    "n_hidden = 256\n",
    "n_input = 28 * 28\n",
    "n_noise = 128\n",
    "n_class = 10\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, n_input])\n",
    "# 노이즈와 실제 이미지에, 그에 해당하는 숫자에 대한 정보를 넣어주기 위해 사용합니다.\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "Z = tf.placeholder(tf.float32, [None, n_noise])\n",
    "\n",
    "def generator(noise, labels):\n",
    "    with tf.variable_scope('generator'):\n",
    "        # noise 값에 labels 정보를 추가합니다.\n",
    "        inputs = tf.concat([noise, labels], 1)\n",
    "\n",
    "        # TensorFlow 에서 제공하는 유틸리티 함수를 이용해 신경망을 매우 간단하게 구성할 수 있습니다.\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                 activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, n_input,\n",
    "                                 activation=tf.nn.sigmoid)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def discriminator(inputs, labels, reuse=None):\n",
    "    with tf.variable_scope('discriminator') as scope:\n",
    "        # 노이즈에서 생성한 이미지와 실제 이미지를 판별하는 모델의 변수를 동일하게 하기 위해,\n",
    "        # 이전에 사용되었던 변수를 재사용하도록 합니다.\n",
    "        if reuse:\n",
    "            scope.reuse_variables()\n",
    "\n",
    "        inputs = tf.concat([inputs, labels], 1)\n",
    "\n",
    "        hidden = tf.layers.dense(inputs, n_hidden,\n",
    "                                 activation=tf.nn.relu)\n",
    "        output = tf.layers.dense(hidden, 1,\n",
    "                                 activation=None)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "def get_noise(batch_size, n_noise):\n",
    "    return np.random.uniform(-1., 1., size=[batch_size, n_noise])\n",
    "\n",
    "# 생성 모델과 판별 모델에 Y 즉, labels 정보를 추가하여\n",
    "# labels 정보에 해당하는 이미지를 생성할 수 있도록 유도합니다.\n",
    "G = generator(Z, Y)\n",
    "D_real = discriminator(X, Y)\n",
    "D_gene = discriminator(G, Y, True)\n",
    "\n",
    "# 손실함수는 다음을 참고하여 GAN 논문에 나온 방식과는 약간 다르게 작성하였습니다.\n",
    "# http://bamos.github.io/2016/08/09/deep-completion/\n",
    "# 진짜 이미지를 판별하는 D_real 값은 1에 가깝도록,\n",
    "# 가짜 이미지를 판별하는 D_gene 값은 0에 가깝도록 하는 손실 함수입니다.\n",
    "loss_D_real = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_real, labels=tf.ones_like(D_real)))\n",
    "loss_D_gene = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.zeros_like(D_gene)))\n",
    "# loss_D_real 과 loss_D_gene 을 더한 뒤 이 값을 최소화 하도록 최적화합니다.\n",
    "loss_D = loss_D_real + loss_D_gene\n",
    "# 가짜 이미지를 진짜에 가깝게 만들도록 생성망을 학습시키기 위해, D_gene 을 최대한 1에 가깝도록 만드는 손실함수입니다.\n",
    "loss_G = tf.reduce_mean(\n",
    "                    tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "                        logits=D_gene, labels=tf.ones_like(D_gene)))\n",
    "\n",
    "# TensorFlow 에서 제공하는 유틸리티 함수를 이용해\n",
    "# discriminator 와 generator scope 에서 사용된 변수들을 쉽게 가져올 수 있습니다.\n",
    "vars_D = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='discriminator')\n",
    "vars_G = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                           scope='generator')\n",
    "\n",
    "train_D = tf.train.AdamOptimizer().minimize(loss_D,\n",
    "                                            var_list=vars_D)\n",
    "train_G = tf.train.AdamOptimizer().minimize(loss_G,\n",
    "                                            var_list=vars_G)\n",
    "print(\"신경망 모델 학습중...\")\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "loss_val_D, loss_val_G = 0, 0\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    print('running epoch ',epoch,'...',end=\"\\r\")\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        noise = get_noise(batch_size, n_noise)\n",
    "\n",
    "        _, loss_val_D = sess.run([train_D, loss_D],\n",
    "                                 feed_dict={X: batch_xs, Y: batch_ys, Z: noise})\n",
    "        _, loss_val_G = sess.run([train_G, loss_G],\n",
    "                                 feed_dict={Y: batch_ys, Z: noise})\n",
    "\n",
    "    print('Epoch:', '%04d' % epoch,\n",
    "          'D loss: {:.4}'.format(loss_val_D),\n",
    "          'G loss: {:.4}'.format(loss_val_G))\n",
    "\n",
    "    #########\n",
    "    # 학습이 되어가는 모습을 보기 위해 주기적으로 레이블에 따른 이미지를 생성하여 저장\n",
    "    ######\n",
    "    if epoch == 0 or (epoch + 1) % 5 == 0:\n",
    "        print(\"generate sample image...\",end=\"\")\n",
    "        sample_size = 10\n",
    "        noise = get_noise(sample_size, n_noise)\n",
    "        samples = sess.run(G,\n",
    "                           feed_dict={Y: mnist.test.labels[:sample_size],\n",
    "                                      Z: noise})\n",
    "\n",
    "        fig, ax = plt.subplots(2, sample_size, figsize=(sample_size, 2))\n",
    "\n",
    "        for i in range(sample_size):\n",
    "            ax[0][i].set_axis_off()\n",
    "            ax[1][i].set_axis_off()\n",
    "\n",
    "            ax[0][i].imshow(np.reshape(mnist.test.images[i], (28, 28)))\n",
    "            ax[1][i].imshow(np.reshape(samples[i], (28, 28)))\n",
    "\n",
    "        plt.savefig('samples2/{}.png'.format(str(epoch).zfill(3)), bbox_inches='tight')\n",
    "        plt.close(fig)\n",
    "        print(\"OK!\")\n",
    "\n",
    "print('최적화 완료!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN\n",
    "- 머신러닝 학습의 Hello World 와 같은 MNIST(손글씨 숫자 인식) 문제를 신경망으로 풀어봅니다.\n",
    "- MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ./mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "Epoch: 0001 Avg. cost = 0.572\n",
      "Epoch: 0002 Avg. cost = 0.242\n",
      "Epoch: 0003 Avg. cost = 0.179\n",
      "Epoch: 0004 Avg. cost = 0.162\n",
      "Epoch: 0005 Avg. cost = 0.136\n",
      "Epoch: 0006 Avg. cost = 0.138\n",
      "Epoch: 0007 Avg. cost = 0.118\n",
      "Epoch: 0008 Avg. cost = 0.109\n",
      "Epoch: 0009 Avg. cost = 0.101\n",
      "Epoch: 0010 Avg. cost = 0.100\n",
      "Epoch: 0011 Avg. cost = 0.098\n",
      "Epoch: 0012 Avg. cost = 0.100\n",
      "Epoch: 0013 Avg. cost = 0.088\n",
      "Epoch: 0014 Avg. cost = 0.083\n",
      "Epoch: 0015 Avg. cost = 0.082\n",
      "Epoch: 0016 Avg. cost = 0.083\n",
      "Epoch: 0017 Avg. cost = 0.078\n",
      "Epoch: 0018 Avg. cost = 0.083\n",
      "Epoch: 0019 Avg. cost = 0.072\n",
      "Epoch: 0020 Avg. cost = 0.073\n",
      "Epoch: 0021 Avg. cost = 0.079\n",
      "Epoch: 0022 Avg. cost = 0.064\n",
      "Epoch: 0023 Avg. cost = 0.065\n",
      "Epoch: 0024 Avg. cost = 0.073\n",
      "Epoch: 0025 Avg. cost = 0.067\n",
      "Epoch: 0026 Avg. cost = 0.068\n",
      "Epoch: 0027 Avg. cost = 0.070\n",
      "Epoch: 0028 Avg. cost = 0.066\n",
      "Epoch: 0029 Avg. cost = 0.060\n",
      "Epoch: 0030 Avg. cost = 0.061\n",
      "최적화 완료!\n",
      "정확도: 0.9749\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"./mnist/data/\", one_hot=True)\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "learning_rate = 0.001\n",
    "total_epoch = 30\n",
    "batch_size = 128\n",
    "\n",
    "# RNN 은 순서가 있는 자료를 다루므로,\n",
    "# 한 번에 입력받는 갯수와, 총 몇 단계로 이루어져있는 데이터를 받을지를 설정해야합니다.\n",
    "# 이를 위해 가로 픽셀수를 n_input 으로, 세로 픽셀수를 입력 단계인 n_step 으로 설정하였습니다.\n",
    "n_input = 28\n",
    "n_step = 28\n",
    "n_hidden = 128\n",
    "n_class = 10\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "Y = tf.placeholder(tf.float32, [None, n_class])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "# RNN 에 학습에 사용할 셀을 생성합니다\n",
    "# 다음 함수들을 사용하면 다른 구조의 셀로 간단하게 변경할 수 있습니다\n",
    "# BasicRNNCell,BasicLSTMCell,GRUCell\n",
    "cell = tf.nn.rnn_cell.BasicRNNCell(n_hidden)\n",
    "\n",
    "# RNN 신경망을 생성합니다\n",
    "# 원래는 다음과 같은 과정을 거쳐야 하지만\n",
    "# states = tf.zeros(batch_size)\n",
    "# for i in range(n_step):\n",
    "#     outputs, states = cell(X[[:, i]], states)\n",
    "# ...\n",
    "# 다음처럼 tf.nn.dynamic_rnn 함수를 사용하면\n",
    "# CNN 의 tf.nn.conv2d 함수처럼 간단하게 RNN 신경망을 만들어줍니다.\n",
    "# 겁나 매직!!\n",
    "outputs, states = tf.nn.dynamic_rnn(cell, X, dtype=tf.float32)\n",
    "\n",
    "# 결과를 Y의 다음 형식과 바꿔야 하기 때문에\n",
    "# Y : [batch_size, n_class]\n",
    "# outputs 의 형태를 이에 맞춰 변경해야합니다.\n",
    "# outputs : [batch_size, n_step, n_hidden]\n",
    "#        -> [n_step, batch_size, n_hidden]\n",
    "#        -> [batch_size, n_hidden]\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=model, labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "total_batch = int(mnist.train.num_examples/batch_size)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    total_cost = 0\n",
    "\n",
    "    for i in range(total_batch):\n",
    "        batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "        # X 데이터를 RNN 입력 데이터에 맞게 [batch_size, n_step, n_input] 형태로 변환합니다.\n",
    "        batch_xs = batch_xs.reshape((batch_size, n_step, n_input))\n",
    "\n",
    "        _, cost_val = sess.run([optimizer, cost],\n",
    "                               feed_dict={X: batch_xs, Y: batch_ys})\n",
    "        total_cost += cost_val\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'Avg. cost =', '{:.3f}'.format(total_cost / total_batch))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "######\n",
    "is_correct = tf.equal(tf.argmax(model, 1), tf.argmax(Y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "test_batch_size = len(mnist.test.images)\n",
    "test_xs = mnist.test.images.reshape(test_batch_size, n_step, n_input)\n",
    "test_ys = mnist.test.labels\n",
    "\n",
    "print('정확도:', sess.run(accuracy,\n",
    "                       feed_dict={X: test_xs, Y: test_ys}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN - Autocomplete\n",
    "- 자연어 처리나 음성 처리 분야에 많이 사용되는 RNN 의 기본적인 사용법을 익힙니다.\n",
    "- 4개의 글자를 가진 단어를 학습시켜, 3글자만 주어지면 나머지 한 글자를 추천하여 단어를 완성하는 프로그램입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost = 4.489306\n",
      "Epoch: 0002 cost = 3.424325\n",
      "Epoch: 0003 cost = 1.803109\n",
      "Epoch: 0004 cost = 1.747030\n",
      "Epoch: 0005 cost = 1.272434\n",
      "Epoch: 0006 cost = 0.656976\n",
      "Epoch: 0007 cost = 0.600736\n",
      "Epoch: 0008 cost = 0.883471\n",
      "Epoch: 0009 cost = 0.492435\n",
      "Epoch: 0010 cost = 0.486881\n",
      "Epoch: 0011 cost = 0.237423\n",
      "Epoch: 0012 cost = 0.408965\n",
      "Epoch: 0013 cost = 0.318964\n",
      "Epoch: 0014 cost = 0.358206\n",
      "Epoch: 0015 cost = 0.109642\n",
      "Epoch: 0016 cost = 0.167461\n",
      "Epoch: 0017 cost = 0.136134\n",
      "Epoch: 0018 cost = 0.103821\n",
      "Epoch: 0019 cost = 0.135834\n",
      "Epoch: 0020 cost = 0.050831\n",
      "Epoch: 0021 cost = 0.133757\n",
      "Epoch: 0022 cost = 0.073349\n",
      "Epoch: 0023 cost = 0.016282\n",
      "Epoch: 0024 cost = 0.107338\n",
      "Epoch: 0025 cost = 0.033539\n",
      "Epoch: 0026 cost = 0.005302\n",
      "Epoch: 0027 cost = 0.073482\n",
      "Epoch: 0028 cost = 0.025233\n",
      "Epoch: 0029 cost = 0.049873\n",
      "Epoch: 0030 cost = 0.056779\n",
      "최적화 완료!\n",
      "\n",
      "=== 예측 결과 ===\n",
      "입력값: ['wo ', 'wo ', 'de ', 'di ', 'co ', 'co ', 'lo ', 'lo ', 'ki ', 'ki ']\n",
      "예측값: ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
      "정확도: 1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "char_arr = ['a', 'b', 'c', 'd', 'e', 'f', 'g',\n",
    "            'h', 'i', 'j', 'k', 'l', 'm', 'n',\n",
    "            'o', 'p', 'q', 'r', 's', 't', 'u',\n",
    "            'v', 'w', 'x', 'y', 'z']\n",
    "\n",
    "# one-hot 인코딩 사용 및 디코딩을 하기 위해 연관 배열을 만듭니다.\n",
    "# {'a': 0, 'b': 1, 'c': 2, ..., 'j': 9, 'k', 10, ...}\n",
    "num_dic = {n: i for i, n in enumerate(char_arr)}\n",
    "dic_len = len(num_dic)\n",
    "\n",
    "# 다음 배열은 입력값과 출력값으로 다음처럼 사용할 것 입니다.\n",
    "# wor -> X, d -> Y\n",
    "# woo -> X, d -> Y\n",
    "seq_data = ['word', 'wood', 'deep', 'dive', 'cold', 'cool', 'load', 'love', 'kiss', 'kind']\n",
    "\n",
    "\n",
    "def make_batch(seq_data):\n",
    "    input_batch = []\n",
    "    target_batch = []\n",
    "\n",
    "    for seq in seq_data:\n",
    "        # 여기서 생성하는 input_batch 와 target_batch 는\n",
    "        # 알파벳 배열의 인덱스 번호 입니다.\n",
    "        # [22, 14, 17] [22, 14, 14] [3, 4, 4] [3, 8, 21] ...\n",
    "        input = [num_dic[n] for n in seq[:-1]]\n",
    "        # 3, 3, 15, 4, 3 ...\n",
    "        target = num_dic[seq[-1]]\n",
    "        # one-hot 인코딩을 합니다.\n",
    "        # if input is [0, 1, 2]:\n",
    "        # [[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "        #  [ 0.  1.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
    "        #  [ 0.  0.  1.  0.  0.  0.  0.  0.  0.  0.]]\n",
    "        input_batch.append(np.eye(dic_len)[input])\n",
    "        # 지금까지 손실함수로 사용하던 softmax_cross_entropy_with_logits 함수는\n",
    "        # label 값을 one-hot 인코딩으로 넘겨줘야 하지만,\n",
    "        # 이 예제에서 사용할 손실 함수인 sparse_softmax_cross_entropy_with_logits 는\n",
    "        # one-hot 인코딩을 사용하지 않으므로 index 를 그냥 넘겨주면 됩니다.\n",
    "        target_batch.append(target)\n",
    "\n",
    "    return input_batch, target_batch\n",
    "\n",
    "#########\n",
    "# 옵션 설정\n",
    "######\n",
    "learning_rate = 0.01\n",
    "n_hidden = 128\n",
    "total_epoch = 30\n",
    "# 타입 스텝: [1 2 3] => 3\n",
    "# RNN 을 구성하는 시퀀스의 갯수입니다.\n",
    "n_step = 3\n",
    "# 입력값 크기. 알파벳에 대한 one-hot 인코딩이므로 26개가 됩니다.\n",
    "# 예) c => [0 0 1 0 0 0 0 0 0 0 0 ... 0]\n",
    "# 출력값도 입력값과 마찬가지로 26개의 알파벳으로 분류합니다.\n",
    "n_input = n_class = dic_len\n",
    "\n",
    "#########\n",
    "# 신경망 모델 구성\n",
    "######\n",
    "X = tf.placeholder(tf.float32, [None, n_step, n_input])\n",
    "# 비용함수에 sparse_softmax_cross_entropy_with_logits 을 사용하므로\n",
    "# 출력값과의 계산을 위한 원본값의 형태는 one-hot vector가 아니라 인덱스 숫자를 그대로 사용하기 때문에\n",
    "# 다음처럼 하나의 값만 있는 1차원 배열을 입력값으로 받습니다.\n",
    "# [3] [3] [15] [4] ...\n",
    "# 기존처럼 one-hot 인코딩을 사용한다면 입력값의 형태는 [None, n_class] 여야합니다.\n",
    "Y = tf.placeholder(tf.int32, [None])\n",
    "\n",
    "W = tf.Variable(tf.random_normal([n_hidden, n_class]))\n",
    "b = tf.Variable(tf.random_normal([n_class]))\n",
    "\n",
    "# RNN 셀을 생성합니다.\n",
    "cell1 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "# 과적합 방지를 위한 Dropout 기법을 사용합니다.\n",
    "cell1 = tf.nn.rnn_cell.DropoutWrapper(cell1, output_keep_prob=0.5)\n",
    "# 여러개의 셀을 조합해서 사용하기 위해 셀을 추가로 생성합니다.\n",
    "cell2 = tf.nn.rnn_cell.BasicLSTMCell(n_hidden)\n",
    "\n",
    "# 여러개의 셀을 조합한 RNN 셀을 생성합니다.\n",
    "multi_cell = tf.nn.rnn_cell.MultiRNNCell([cell1, cell2])\n",
    "\n",
    "# tf.nn.dynamic_rnn 함수를 이용해 순환 신경망을 만듭니다.\n",
    "# time_major=True\n",
    "outputs, states = tf.nn.dynamic_rnn(multi_cell, X, dtype=tf.float32)\n",
    "\n",
    "# 최종 결과는 one-hot 인코딩 형식으로 만듭니다\n",
    "outputs = tf.transpose(outputs, [1, 0, 2])\n",
    "outputs = outputs[-1]\n",
    "model = tf.matmul(outputs, W) + b\n",
    "\n",
    "cost = tf.reduce_mean(\n",
    "            tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "                logits=model, labels=Y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "#########\n",
    "# 신경망 모델 학습\n",
    "######\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "for epoch in range(total_epoch):\n",
    "    _, loss = sess.run([optimizer, cost],\n",
    "                       feed_dict={X: input_batch, Y: target_batch})\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1),\n",
    "          'cost =', '{:.6f}'.format(loss))\n",
    "\n",
    "print('최적화 완료!')\n",
    "\n",
    "#########\n",
    "# 결과 확인\n",
    "######\n",
    "# 레이블값이 정수이므로 예측값도 정수로 변경해줍니다.\n",
    "prediction = tf.cast(tf.argmax(model, 1), tf.int32)\n",
    "# one-hot 인코딩이 아니므로 입력값을 그대로 비교합니다.\n",
    "prediction_check = tf.equal(prediction, Y)\n",
    "accuracy = tf.reduce_mean(tf.cast(prediction_check, tf.float32))\n",
    "\n",
    "input_batch, target_batch = make_batch(seq_data)\n",
    "\n",
    "predict, accuracy_val = sess.run([prediction, accuracy],\n",
    "                                 feed_dict={X: input_batch, Y: target_batch})\n",
    "\n",
    "predict_words = []\n",
    "for idx, val in enumerate(seq_data):\n",
    "    last_char = char_arr[predict[idx]]\n",
    "    predict_words.append(val[:3] + last_char)\n",
    "\n",
    "print('\\n=== 예측 결과 ===')\n",
    "print('입력값:', [w[:3] + ' ' for w in seq_data])\n",
    "print('예측값:', predict_words)\n",
    "print('정확도:', accuracy_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
