{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output # clear_output() 으로 아웃풋 제거 가능\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"last\" # all\n",
    "\n",
    "import warnings # 경고가 너무 많이뜨는경우 주피터가 죽음.... 아래 주석 해제하여 워닝끄면 됨\n",
    "# warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.stats.api as sms\n",
    "import sklearn as sk\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_formats = {'png','retina'}\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pylab as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_color_codes()\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "#한글폰트 적용\n",
    "from matplotlib import font_manager, rc\n",
    "font_name = font_manager.FontProperties(fname=\"c:/Windows/Fonts/malgun.ttf\").get_name()\n",
    "rc('font', family=font_name)\n",
    "#음수처리\n",
    "mpl.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 딥러닝 텐서플로 코드 기본형들\n",
    "- CNN - VGG\n",
    "- RNN\n",
    "- LSTM\n",
    "- GRU\n",
    "- GAN\n",
    "- DCGAN\n",
    "- Q-learning\n",
    "- DQN\n",
    "\n",
    "\n",
    "- 기타 intro 내용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. CNN\n",
    "- cifar10 CNN\n",
    "- MNIST + Saver Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cifar 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting cifar10 data.., done!\n",
      "building classifier...with BN\n",
      "======== Session start! ========\n",
      "training_set : 50000, test_set : 10000\n",
      "반복(Epoch):0, 트레이닝 정확도:0.101562, 손실함수(loss):3.294119      \n",
      "반복(Epoch):99 학습종료!=\n",
      "\n",
      "(테스트 데이터 정확도: 0.453125)\n"
     ]
    }
   ],
   "source": [
    "# cifar10 CNN\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    `num`갯수만큼의 랜덤한 샘플과 레이블을 리턴합니다.\n",
    "    '''\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx=idx[:num]\n",
    "    data_shuffle = [data[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "epsilon = 1e-3\n",
    "\n",
    "def batch_norm_wrapper(inputs, is_training, decay = 0.999):\n",
    "    \n",
    "    scale = tf.Variable(tf.ones(inputs.get_shape()[-3:]))\n",
    "    beta = tf.Variable(tf.zeros(inputs.get_shape()[-3:]))\n",
    "    pop_mean = tf.Variable(tf.zeros(inputs.get_shape()[-3:]), trainable=False)\n",
    "    pop_var = tf.Variable(tf.ones(inputs.get_shape()[-3:]), trainable=False)\n",
    "#     print(inputs.get_shape()[-3:],scale, beta, pop_mean, pop_var)\n",
    "    if is_training:\n",
    "        batch_mean, batch_var = tf.nn.moments(inputs,[0])\n",
    "        train_mean = tf.assign(pop_mean,\n",
    "                               pop_mean * decay + batch_mean * (1 - decay))\n",
    "        train_var = tf.assign(pop_var,\n",
    "                              pop_var * decay + batch_var * (1 - decay))\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(inputs,\n",
    "                batch_mean, batch_var, beta, scale, epsilon)\n",
    "    else:\n",
    "        return tf.nn.batch_normalization(inputs,\n",
    "            pop_mean, pop_var, beta, scale, epsilon)\n",
    "\n",
    "def build_CNN_classifier(x,is_training=False): # VGG모델기준인듯\n",
    "    x_image = x\n",
    "    \n",
    "    # L1 ----------------\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,3,64], stddev=5e-2))\n",
    "    b_conv1 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    r_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME')+b_conv1\n",
    "    BN1 = batch_norm_wrapper(r_conv1,is_training)\n",
    "    h_conv1 = tf.nn.relu(BN1)\n",
    "    h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # L2 -----------------\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,64,64], stddev=5e-2))\n",
    "    b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    r_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1,1,1,1], padding='SAME')+b_conv2\n",
    "    BN2 = batch_norm_wrapper(r_conv2,is_training)\n",
    "    h_conv2 = tf.nn.relu(BN2)\n",
    "    h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # L3 ------------------\n",
    "    W_conv3 = tf.Variable(tf.truncated_normal(shape=[3,3,64,128],stddev=5e-2))\n",
    "    b_conv3 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "    r_conv3 = tf.nn.conv2d(h_pool2, W_conv3, strides=[1,1,1,1], padding='SAME')+b_conv3\n",
    "    BN3 = batch_norm_wrapper(r_conv3,is_training)\n",
    "    h_conv3 = tf.nn.relu(BN3)\n",
    "    \n",
    "    # L4 ------------------\n",
    "    W_conv4 = tf.Variable(tf.truncated_normal(shape=[3,3,128,128],stddev=5e-2))\n",
    "    b_conv4 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "    r_conv4 = tf.nn.conv2d(h_conv3, W_conv4, strides=[1,1,1,1], padding='SAME')+b_conv4\n",
    "    BN4 = batch_norm_wrapper(r_conv4,is_training)\n",
    "    h_conv4 = tf.nn.relu(BN4)\n",
    "    \n",
    "    # L5 ------------------\n",
    "    W_conv5 = tf.Variable(tf.truncated_normal(shape=[3,3,128,128],stddev=5e-2))\n",
    "    b_conv5 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "    r_conv5 = tf.nn.conv2d(h_conv4, W_conv5, strides=[1,1,1,1], padding='SAME')+b_conv5\n",
    "    BN5 = batch_norm_wrapper(r_conv5,is_training)\n",
    "    h_conv5 = tf.nn.relu(BN5)  \n",
    "    \n",
    "    # Fully con Laver1 -----\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal(shape=[8*8*128,384],stddev=5e-2))\n",
    "    b_fc1 = tf.Variable(tf.constant(0.1,shape=[384]))\n",
    "    \n",
    "    h_conv5_flat = tf.reshape(h_conv5, [-1, 8*8*128])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1)+b_fc1)\n",
    "    \n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    \n",
    "    # mapping --------------\n",
    "    W_fc2 = tf.Variable(tf.truncated_normal(shape=[384,10], stddev=5e-2))\n",
    "    b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "    logits = tf.matmul(h_fc1_drop,W_fc2)+b_fc2\n",
    "    y_pred = tf.nn.softmax(logits)\n",
    "    \n",
    "    return y_pred, logits\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 32,32,3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# CIFAR10 data load!\n",
    "print(\"getting cifar10 data..\", end =\"\")\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "y_train_one_hot = tf.squeeze(tf.one_hot(y_train,10),axis=1)\n",
    "y_test_one_hot = tf.squeeze(tf.one_hot(y_test,10),axis=1)\n",
    "print(\", done!\")\n",
    "\n",
    "print(\"building classifier...with BN\")\n",
    "y_pred, logits = build_CNN_classifier(x,True)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "train_step = tf.train.RMSPropOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "print(\"======== Session start! ========\")\n",
    "\n",
    "print(\"training_set : %d, test_set : %d\"%(len(x_train),len(x_test)))\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4 # GPU메모리 적용 % 설정\n",
    "\n",
    "with tf.Session(config=config) as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(100):\n",
    "        batch = next_batch(256, x_train, y_train_one_hot.eval())\n",
    "        if i % 10 == 0 : \n",
    "            print(\"=\",end=\"\")\n",
    "        if i % 400 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict = {x:batch[0], y:batch[1],keep_prob:1.0})\n",
    "            loss_print = loss.eval(feed_dict ={x:batch[0], y:batch[1], keep_prob:1.0})\n",
    "            print(\"\\r반복(Epoch):%d, 트레이닝 정확도:%f, 손실함수(loss):%f      \"%(i,train_accuracy,loss_print))\n",
    "            print(\"반복(Epoch):\",end=\"\")\n",
    "            \n",
    "        #20%확률로 Dropout 실행\n",
    "        sess.run(train_step, feed_dict={x:batch[0], y:batch[1],keep_prob:0.8})\n",
    "        \n",
    "    #학습이 끝나면 정확도 출력!\n",
    "    test_batch = next_batch(512, x_test, y_test_one_hot.eval())\n",
    "    print(\"\\r반복(Epoch):%d\"%i,\"학습종료!\\n\\n(테스트 데이터 정확도: %f)\" % accuracy.eval(feed_dict={x: test_batch[0], y: test_batch[1], keep_prob: 1.0}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting cifar10 data.., done!\n",
      "building classifier...with BN\n",
      "======== Session start! ========\n",
      "training_set : 50000, test_set : 10000\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Cannot assign a device for operation 'truncated_normal_101/TruncatedNormal': Operation was explicitly assigned to /device:GPU:1 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: truncated_normal_101/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/device:GPU:1\"](truncated_normal_101/shape)]]\n\nCaused by op 'truncated_normal_101/TruncatedNormal', defined at:\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-38-61681a1f2301>\", line 117, in <module>\n    y_pred, logits = build_CNN_classifier(x,True)\n  File \"<ipython-input-38-61681a1f2301>\", line 49, in build_CNN_classifier\n    W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,3,64], stddev=5e-2))\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 174, in truncated_normal\n    shape_tensor, dtype, seed=seed1, seed2=seed2)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 908, in truncated_normal\n    name=name)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'truncated_normal_101/TruncatedNormal': Operation was explicitly assigned to /device:GPU:1 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: truncated_normal_101/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/device:GPU:1\"](truncated_normal_101/shape)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1260\u001b[0m       \u001b[1;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1261\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1294\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1295\u001b[1;33m       \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'truncated_normal_101/TruncatedNormal': Operation was explicitly assigned to /device:GPU:1 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: truncated_normal_101/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/device:GPU:1\"](truncated_normal_101/shape)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-61681a1f2301>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m     \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Cannot assign a device for operation 'truncated_normal_101/TruncatedNormal': Operation was explicitly assigned to /device:GPU:1 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: truncated_normal_101/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/device:GPU:1\"](truncated_normal_101/shape)]]\n\nCaused by op 'truncated_normal_101/TruncatedNormal', defined at:\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-38-61681a1f2301>\", line 117, in <module>\n    y_pred, logits = build_CNN_classifier(x,True)\n  File \"<ipython-input-38-61681a1f2301>\", line 49, in build_CNN_classifier\n    W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,3,64], stddev=5e-2))\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\random_ops.py\", line 174, in truncated_normal\n    shape_tensor, dtype, seed=seed1, seed2=seed2)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_random_ops.py\", line 908, in truncated_normal\n    name=name)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): Cannot assign a device for operation 'truncated_normal_101/TruncatedNormal': Operation was explicitly assigned to /device:GPU:1 but available devices are [ /job:localhost/replica:0/task:0/device:CPU:0, /job:localhost/replica:0/task:0/device:GPU:0 ]. Make sure the device specification refers to a valid device.\n\t [[Node: truncated_normal_101/TruncatedNormal = TruncatedNormal[T=DT_INT32, dtype=DT_FLOAT, seed=0, seed2=0, _device=\"/device:GPU:1\"](truncated_normal_101/shape)]]\n"
     ]
    }
   ],
   "source": [
    "# cifar10 CNN + multi gpu\n",
    "\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import os\n",
    "from tensorflow.keras.datasets.cifar10 import load_data\n",
    "\n",
    "def next_batch(num, data, labels):\n",
    "    '''\n",
    "    `num`갯수만큼의 랜덤한 샘플과 레이블을 리턴합니다.\n",
    "    '''\n",
    "    idx = np.arange(0, len(data))\n",
    "    np.random.shuffle(idx)\n",
    "    idx=idx[:num]\n",
    "    data_shuffle = [data[i] for i in idx]\n",
    "    labels_shuffle = [labels[i] for i in idx]\n",
    "\n",
    "    return np.asarray(data_shuffle), np.asarray(labels_shuffle)\n",
    "\n",
    "epsilon = 1e-3\n",
    "\n",
    "def batch_norm_wrapper(inputs, is_training, decay = 0.999):\n",
    "    \n",
    "    scale = tf.Variable(tf.ones(inputs.get_shape()[-3:]))\n",
    "    beta = tf.Variable(tf.zeros(inputs.get_shape()[-3:]))\n",
    "    pop_mean = tf.Variable(tf.zeros(inputs.get_shape()[-3:]), trainable=False)\n",
    "    pop_var = tf.Variable(tf.ones(inputs.get_shape()[-3:]), trainable=False)\n",
    "#     print(inputs.get_shape()[-3:],scale, beta, pop_mean, pop_var)\n",
    "    if is_training:\n",
    "        batch_mean, batch_var = tf.nn.moments(inputs,[0])\n",
    "        train_mean = tf.assign(pop_mean,\n",
    "                               pop_mean * decay + batch_mean * (1 - decay))\n",
    "        train_var = tf.assign(pop_var,\n",
    "                              pop_var * decay + batch_var * (1 - decay))\n",
    "        with tf.control_dependencies([train_mean, train_var]):\n",
    "            return tf.nn.batch_normalization(inputs,\n",
    "                batch_mean, batch_var, beta, scale, epsilon)\n",
    "    else:\n",
    "        return tf.nn.batch_normalization(inputs,\n",
    "            pop_mean, pop_var, beta, scale, epsilon)\n",
    "\n",
    "def build_CNN_classifier(x,is_training=False): # VGG모델기준인듯\n",
    "    x_image = x\n",
    "    \n",
    "    c = []\n",
    "    for d in ['/gpu:0', '/gpu:1']:\n",
    "        with tf.device(d):\n",
    "            # L1 ----------------\n",
    "            W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,3,64], stddev=5e-2))\n",
    "            b_conv1 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "            r_conv1 = tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME')+b_conv1\n",
    "            BN1 = batch_norm_wrapper(r_conv1,is_training)\n",
    "            h_conv1 = tf.nn.relu(BN1)\n",
    "            h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "            # L2 -----------------\n",
    "            W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,64,64], stddev=5e-2))\n",
    "            b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "            r_conv2 = tf.nn.conv2d(h_pool1, W_conv2, strides=[1,1,1,1], padding='SAME')+b_conv2\n",
    "            BN2 = batch_norm_wrapper(r_conv2,is_training)\n",
    "            h_conv2 = tf.nn.relu(BN2)\n",
    "            h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1,3,3,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "            # L3 ------------------\n",
    "            W_conv3 = tf.Variable(tf.truncated_normal(shape=[3,3,64,128],stddev=5e-2))\n",
    "            b_conv3 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "            r_conv3 = tf.nn.conv2d(h_pool2, W_conv3, strides=[1,1,1,1], padding='SAME')+b_conv3\n",
    "            BN3 = batch_norm_wrapper(r_conv3,is_training)\n",
    "            h_conv3 = tf.nn.relu(BN3)\n",
    "\n",
    "            # L4 ------------------\n",
    "            W_conv4 = tf.Variable(tf.truncated_normal(shape=[3,3,128,128],stddev=5e-2))\n",
    "            b_conv4 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "            r_conv4 = tf.nn.conv2d(h_conv3, W_conv4, strides=[1,1,1,1], padding='SAME')+b_conv4\n",
    "            BN4 = batch_norm_wrapper(r_conv4,is_training)\n",
    "            h_conv4 = tf.nn.relu(BN4)\n",
    "\n",
    "            # L5 ------------------\n",
    "            W_conv5 = tf.Variable(tf.truncated_normal(shape=[3,3,128,128],stddev=5e-2))\n",
    "            b_conv5 = tf.Variable(tf.constant(0.1, shape=[128]))\n",
    "            r_conv5 = tf.nn.conv2d(h_conv4, W_conv5, strides=[1,1,1,1], padding='SAME')+b_conv5\n",
    "            BN5 = batch_norm_wrapper(r_conv5,is_training)\n",
    "            h_conv5 = tf.nn.relu(BN5)  \n",
    "\n",
    "            # Fully con Laver1 -----\n",
    "            W_fc1 = tf.Variable(tf.truncated_normal(shape=[8*8*128,384],stddev=5e-2))\n",
    "            b_fc1 = tf.Variable(tf.constant(0.1,shape=[384]))\n",
    "\n",
    "            h_conv5_flat = tf.reshape(h_conv5, [-1, 8*8*128])\n",
    "            h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1)+b_fc1)\n",
    "\n",
    "            h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "            # mapping --------------\n",
    "            W_fc2 = tf.Variable(tf.truncated_normal(shape=[384,10], stddev=5e-2))\n",
    "            b_fc2 = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "            c.append(tf.matmul(h_fc1_drop,W_fc2)+b_fc2)\n",
    "            \n",
    "    with tf.device('/cpu:0'):\n",
    "        logits = tf.add_n(c)\n",
    "        y_pred = tf.nn.softmax(logits)   \n",
    "    \n",
    "    return y_pred, logits\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 32,32,3])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "# CIFAR10 data load!\n",
    "print(\"getting cifar10 data..\", end =\"\")\n",
    "(x_train, y_train), (x_test, y_test) = load_data()\n",
    "y_train_one_hot = tf.squeeze(tf.one_hot(y_train,10),axis=1)\n",
    "y_test_one_hot = tf.squeeze(tf.one_hot(y_test,10),axis=1)\n",
    "print(\", done!\")\n",
    "\n",
    "print(\"building classifier...with BN\")\n",
    "y_pred, logits = build_CNN_classifier(x,True)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "train_step = tf.train.RMSPropOptimizer(1e-3).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "print(\"======== Session start! ========\")\n",
    "\n",
    "print(\"training_set : %d, test_set : %d\"%(len(x_train),len(x_test)))\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4 # GPU메모리 적용 % 설정\n",
    "\n",
    "with tf.Session(config=config) as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for i in range(5000):\n",
    "        batch = next_batch(128, x_train, y_train_one_hot.eval())\n",
    "        if i % 10 == 0 : \n",
    "            print(\"=\",end=\"\")\n",
    "        if i % 500 == 0:\n",
    "            train_accuracy = accuracy.eval(feed_dict = {x:batch[0], y:batch[1],keep_prob:1.0})\n",
    "            loss_print = loss.eval(feed_dict ={x:batch[0], y:batch[1], keep_prob:1.0})\n",
    "            print(\"\\r반복(Epoch):%d, - %s sec, 트레이닝 정확도:%f, 손실함수(loss):%f      \"%(i,(time.time()-start_time),train_accuracy,loss_print))\n",
    "            print(\"반복(Epoch):\",end=\"\")\n",
    "            start_time = time.time()\n",
    "            \n",
    "        #20%확률로 Dropout 실행\n",
    "        sess.run(train_step, feed_dict={x:batch[0], y:batch[1],keep_prob:0.8})\n",
    "        \n",
    "    #학습이 끝나면 정확도 출력!\n",
    "    test_batch = next_batch(512, x_test, y_test_one_hot.eval())\n",
    "    print(\"\\r반복(Epoch):%d\"%i,\"학습종료!\\n\\n(00테스트 데이터 정확도: %f)\" % accuracy.eval(feed_dict={x: test_batch[0], y: test_batch[1], keep_prob: 1.0}))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = []\n",
    "for d in ['/gpu:2', '/gpu:3']:\n",
    "    with tf.device(d):\n",
    "        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3])\n",
    "        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2])\n",
    "        c.append(tf.matmul(a, b))\n",
    "with tf.device('/cpu:0'):\n",
    "    sum = tf.add_n(c)\n",
    "# log_device_placement을 True로 설정하여 세션을 만듭니다.\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "# op를 실행합니다.\n",
    "print sess.run(sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mnist CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# MNIST와 Saver를 활용한 CNN 분류기\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "print(\"getting mnist data..\", end =\"\")\n",
    "mnist = input_data.read_data_sets(\"D:/mnist/data/\", one_hot=True)\n",
    "print(\"done!\")\n",
    "\n",
    "def build_CNN_classifier(x):\n",
    "    x_image = tf.reshape(x, [-1,28,28,1])\n",
    "    \n",
    "    # L1 -----\n",
    "    W_conv1 = tf.Variable(tf.truncated_normal(shape=[5,5,1,32],stddev=5e-2))\n",
    "    b_conv1 = tf.Variable(tf.constant(0.1, shape=[32]))\n",
    "    h_conv1 = tf.nn.relu(tf.nn.conv2d(x_image, W_conv1, strides=[1,1,1,1], padding='SAME') + b_conv1)\n",
    "    \n",
    "    h_pool1 = tf.nn.max_pool(h_conv1, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # L2 -----\n",
    "    W_conv2 = tf.Variable(tf.truncated_normal(shape=[5,5,32,64],stddev=5e-2))\n",
    "    b_conv2 = tf.Variable(tf.constant(0.1, shape=[64]))\n",
    "    h_conv2 = tf.nn.relu(tf.nn.conv2d(h_pool1, W_conv2, strides=[1,1,1,1], padding='SAME') + b_conv2)\n",
    "    \n",
    "    h_pool2 = tf.nn.max_pool(h_conv2, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "    \n",
    "    # L3 ------ (Full connected layer)\n",
    "    W_fc1 = tf.Variable(tf.truncated_normal(shape=[7*7*64,1024], stddev=5e-2))\n",
    "    b_fc1 = tf.Variable(tf.constant(0.1, shape=[1024]))\n",
    "    h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "    h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "    \n",
    "    # OUTPUT L -----\n",
    "    W_output = tf.Variable(tf.truncated_normal(shape=[1024,10], stddev=5e-2))\n",
    "    b_output = tf.Variable(tf.constant(0.1, shape=[10]))\n",
    "    logits = tf.matmul(h_fc1, W_output) + b_output\n",
    "    y_pred = tf.nn.softmax(logits)\n",
    "    \n",
    "    return y_pred, logits\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "y_pred, logits = build_CNN_classifier(x)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=logits))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred, 1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print(\"---- saver load ----\")\n",
    "\n",
    "SAVER_DIR = \"model2\"\n",
    "saver = tf.train.Saver()#tf.global_variables()\n",
    "checkpoint_path = os.path.join(SAVER_DIR, \"model2\")\n",
    "ckpt = tf.train.get_checkpoint_state(SAVER_DIR)\n",
    "\n",
    "print(\"======== Session start! ========\")\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "    \n",
    "with tf.Session(config=config) as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    if ckpt and ckpt.model_checkpoint_path:\n",
    "        print(\"saved file finded!\")\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        print(\"테스트 데이터 정확도 (Restored) : %f\" % accuracy.eval(feed_dict={x:mnist.test.images, y:mnist.test.labels}))\n",
    "        sess.close()\n",
    "        exit()\n",
    "        \n",
    "    for step in range(2000):\n",
    "        batch = mnist.train.next_batch(128)\n",
    "        print(\"반복(Epoch): %d\"%step,end=\"   \\r\")\n",
    "        if step % 512 == 0:\n",
    "            trash = saver.save(sess, checkpoint_path, global_step=step)\n",
    "            train_accuracy = accuracy.eval(feed_dict={x: batch[0], y:batch[1]})\n",
    "            print(\"반복(Epoch): %d, 트레이닝 데이터 정확도 %f\"%(step, train_accuracy))\n",
    "        \n",
    "        trash = sess.run([train_step], feed_dict={x:batch[0],y:batch[1]})\n",
    "        \n",
    "    print(\"학습완료// test data 정확도 : %f\" % accuracy.eval(feed_dict={x:mnist.test.images,y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n. intro\n",
    "- Stacked Autoencoders + Softmax Classifier 예제\n",
    "- ANN (기본)\n",
    "- Autoencoder\n",
    "- softmax regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting mnist data..Extracting D:/mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting D:/mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting D:/mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting D:/mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "done!\n",
      "======== Session start! ========\n",
      "반복(Epoch): 1, Pre-Training 손실 함수(pretraining_loss): 0.191293\n",
      "반복(Epoch): 2, Pre-Training 손실 함수(pretraining_loss): 0.121293\n",
      "반복(Epoch): 3, Pre-Training 손실 함수(pretraining_loss): 0.104755\n",
      "반복(Epoch): 4, Pre-Training 손실 함수(pretraining_loss): 0.097065\n",
      "반복(Epoch): 5, Pre-Training 손실 함수(pretraining_loss): 0.084432\n",
      "반복(Epoch): 6, Pre-Training 손실 함수(pretraining_loss): 0.080039\n",
      "반복(Epoch): 7, Pre-Training 손실 함수(pretraining_loss): 0.071801\n",
      "반복(Epoch): 8, Pre-Training 손실 함수(pretraining_loss): 0.073721\n",
      "반복(Epoch): 9, Pre-Training 손실 함수(pretraining_loss): 0.070584\n",
      "반복(Epoch): 10, Pre-Training 손실 함수(pretraining_loss): 0.064002\n",
      "반복(Epoch): 11, Pre-Training 손실 함수(pretraining_loss): 0.063793\n",
      "반복(Epoch): 12, Pre-Training 손실 함수(pretraining_loss): 0.060310\n",
      "반복(Epoch): 13, Pre-Training 손실 함수(pretraining_loss): 0.062282\n",
      "반복(Epoch): 14, Pre-Training 손실 함수(pretraining_loss): 0.060671\n",
      "반복(Epoch): 15, Pre-Training 손실 함수(pretraining_loss): 0.057007\n",
      "반복(Epoch): 16, Pre-Training 손실 함수(pretraining_loss): 0.050728\n",
      "반복(Epoch): 17, Pre-Training 손실 함수(pretraining_loss): 0.048182\n",
      "반복(Epoch): 18, Pre-Training 손실 함수(pretraining_loss): 0.049128\n",
      "반복(Epoch): 19, Pre-Training 손실 함수(pretraining_loss): 0.049483\n",
      "반복(Epoch): 20, Pre-Training 손실 함수(pretraining_loss): 0.044348\n",
      "반복(Epoch): 21, Pre-Training 손실 함수(pretraining_loss): 0.045132\n",
      "반복(Epoch): 22, Pre-Training 손실 함수(pretraining_loss): 0.042901\n",
      "반복(Epoch): 23, Pre-Training 손실 함수(pretraining_loss): 0.042723\n",
      "반복(Epoch): 24, Pre-Training 손실 함수(pretraining_loss): 0.039942\n",
      "반복(Epoch): 25, Pre-Training 손실 함수(pretraining_loss): 0.042337\n",
      "반복(Epoch): 26, Pre-Training 손실 함수(pretraining_loss): 0.040771\n",
      "반복(Epoch): 27, Pre-Training 손실 함수(pretraining_loss): 0.042691\n",
      "반복(Epoch): 28, Pre-Training 손실 함수(pretraining_loss): 0.039985\n",
      "반복(Epoch): 29, Pre-Training 손실 함수(pretraining_loss): 0.039054\n",
      "반복(Epoch): 30, Pre-Training 손실 함수(pretraining_loss): 0.035972\n",
      "반복(Epoch): 31, Pre-Training 손실 함수(pretraining_loss): 0.038638\n",
      "반복(Epoch): 32, Pre-Training 손실 함수(pretraining_loss): 0.036516\n",
      "반복(Epoch): 33, Pre-Training 손실 함수(pretraining_loss): 0.035947\n",
      "반복(Epoch): 34, Pre-Training 손실 함수(pretraining_loss): 0.036487\n",
      "반복(Epoch): 35, Pre-Training 손실 함수(pretraining_loss): 0.036850\n",
      "반복(Epoch): 36, Pre-Training 손실 함수(pretraining_loss): 0.037130\n",
      "반복(Epoch): 37, Pre-Training 손실 함수(pretraining_loss): 0.034618\n",
      "반복(Epoch): 38, Pre-Training 손실 함수(pretraining_loss): 0.036731\n",
      "반복(Epoch): 39, Pre-Training 손실 함수(pretraining_loss): 0.033501\n",
      "반복(Epoch): 40, Pre-Training 손실 함수(pretraining_loss): 0.032293\n",
      "반복(Epoch): 41, Pre-Training 손실 함수(pretraining_loss): 0.031994\n",
      "반복(Epoch): 42, Pre-Training 손실 함수(pretraining_loss): 0.031989\n",
      "반복(Epoch): 43, Pre-Training 손실 함수(pretraining_loss): 0.033085\n",
      "반복(Epoch): 44, Pre-Training 손실 함수(pretraining_loss): 0.030907\n",
      "반복(Epoch): 45, Pre-Training 손실 함수(pretraining_loss): 0.030690\n",
      "반복(Epoch): 46, Pre-Training 손실 함수(pretraining_loss): 0.033700\n",
      "반복(Epoch): 47, Pre-Training 손실 함수(pretraining_loss): 0.032100\n",
      "반복(Epoch): 48, Pre-Training 손실 함수(pretraining_loss): 0.032243\n",
      "반복(Epoch): 49, Pre-Training 손실 함수(pretraining_loss): 0.031251\n",
      "반복(Epoch): 50, Pre-Training 손실 함수(pretraining_loss): 0.030722\n",
      "반복(Epoch): 51, Pre-Training 손실 함수(pretraining_loss): 0.031736\n",
      "반복(Epoch): 52, Pre-Training 손실 함수(pretraining_loss): 0.028505\n",
      "반복(Epoch): 53, Pre-Training 손실 함수(pretraining_loss): 0.029313\n",
      "반복(Epoch): 54, Pre-Training 손실 함수(pretraining_loss): 0.028025\n",
      "반복(Epoch): 55, Pre-Training 손실 함수(pretraining_loss): 0.029480\n",
      "반복(Epoch): 56, Pre-Training 손실 함수(pretraining_loss): 0.028334\n",
      "반복(Epoch): 57, Pre-Training 손실 함수(pretraining_loss): 0.029836\n",
      "반복(Epoch): 58, Pre-Training 손실 함수(pretraining_loss): 0.027237\n",
      "반복(Epoch): 59, Pre-Training 손실 함수(pretraining_loss): 0.025238\n",
      "반복(Epoch): 60, Pre-Training 손실 함수(pretraining_loss): 0.028595\n",
      "반복(Epoch): 61, Pre-Training 손실 함수(pretraining_loss): 0.027229\n",
      "반복(Epoch): 62, Pre-Training 손실 함수(pretraining_loss): 0.022627\n",
      "반복(Epoch): 63, Pre-Training 손실 함수(pretraining_loss): 0.022240\n",
      "반복(Epoch): 64, Pre-Training 손실 함수(pretraining_loss): 0.023764\n",
      "반복(Epoch): 65, Pre-Training 손실 함수(pretraining_loss): 0.024118\n",
      "반복(Epoch): 66, Pre-Training 손실 함수(pretraining_loss): 0.021796\n",
      "반복(Epoch): 67, Pre-Training 손실 함수(pretraining_loss): 0.021202\n",
      "반복(Epoch): 68, Pre-Training 손실 함수(pretraining_loss): 0.019872\n",
      "반복(Epoch): 69, Pre-Training 손실 함수(pretraining_loss): 0.021956\n",
      "반복(Epoch): 70, Pre-Training 손실 함수(pretraining_loss): 0.019385\n",
      "반복(Epoch): 71, Pre-Training 손실 함수(pretraining_loss): 0.019748\n",
      "반복(Epoch): 72, Pre-Training 손실 함수(pretraining_loss): 0.020210\n",
      "반복(Epoch): 73, Pre-Training 손실 함수(pretraining_loss): 0.021574\n",
      "반복(Epoch): 74, Pre-Training 손실 함수(pretraining_loss): 0.019156\n",
      "반복(Epoch): 75, Pre-Training 손실 함수(pretraining_loss): 0.018591\n",
      "반복(Epoch): 76, Pre-Training 손실 함수(pretraining_loss): 0.018770\n",
      "반복(Epoch): 77, Pre-Training 손실 함수(pretraining_loss): 0.019837\n",
      "반복(Epoch): 78, Pre-Training 손실 함수(pretraining_loss): 0.019176\n",
      "반복(Epoch): 79, Pre-Training 손실 함수(pretraining_loss): 0.019366\n",
      "반복(Epoch): 80, Pre-Training 손실 함수(pretraining_loss): 0.020722\n",
      "반복(Epoch): 81, Pre-Training 손실 함수(pretraining_loss): 0.017949\n",
      "반복(Epoch): 82, Pre-Training 손실 함수(pretraining_loss): 0.017672\n",
      "반복(Epoch): 83, Pre-Training 손실 함수(pretraining_loss): 0.017457\n",
      "반복(Epoch): 84, Pre-Training 손실 함수(pretraining_loss): 0.018265\n",
      "반복(Epoch): 85, Pre-Training 손실 함수(pretraining_loss): 0.017477\n",
      "반복(Epoch): 86, Pre-Training 손실 함수(pretraining_loss): 0.018295\n",
      "반복(Epoch): 87, Pre-Training 손실 함수(pretraining_loss): 0.017539\n",
      "반복(Epoch): 88, Pre-Training 손실 함수(pretraining_loss): 0.018066\n",
      "반복(Epoch): 89, Pre-Training 손실 함수(pretraining_loss): 0.019126\n",
      "반복(Epoch): 90, Pre-Training 손실 함수(pretraining_loss): 0.018295\n",
      "반복(Epoch): 91, Pre-Training 손실 함수(pretraining_loss): 0.018186\n",
      "반복(Epoch): 92, Pre-Training 손실 함수(pretraining_loss): 0.018231\n",
      "반복(Epoch): 93, Pre-Training 손실 함수(pretraining_loss): 0.019479\n",
      "반복(Epoch): 94, Pre-Training 손실 함수(pretraining_loss): 0.018100\n",
      "반복(Epoch): 95, Pre-Training 손실 함수(pretraining_loss): 0.018443\n",
      "반복(Epoch): 96, Pre-Training 손실 함수(pretraining_loss): 0.018982\n",
      "반복(Epoch): 97, Pre-Training 손실 함수(pretraining_loss): 0.018416\n",
      "반복(Epoch): 98, Pre-Training 손실 함수(pretraining_loss): 0.018536\n",
      "반복(Epoch): 99, Pre-Training 손실 함수(pretraining_loss): 0.017755\n",
      "반복(Epoch): 100, Pre-Training 손실 함수(pretraining_loss): 0.016473\n",
      "Step 1: MNIST 데이터 재구축을 위한 오토인코더 최적화 완료(Pre-Training)-----\n",
      "반복(Epoch): 1, Fine-tuning 손실 함수(finetuning_loss): 0.439776\n",
      "반복(Epoch): 2, Fine-tuning 손실 함수(finetuning_loss): 0.362891\n",
      "반복(Epoch): 3, Fine-tuning 손실 함수(finetuning_loss): 0.353742\n",
      "반복(Epoch): 4, Fine-tuning 손실 함수(finetuning_loss): 0.297596\n",
      "반복(Epoch): 5, Fine-tuning 손실 함수(finetuning_loss): 0.250706\n",
      "반복(Epoch): 6, Fine-tuning 손실 함수(finetuning_loss): 0.291765\n",
      "반복(Epoch): 7, Fine-tuning 손실 함수(finetuning_loss): 0.227097\n",
      "반복(Epoch): 8, Fine-tuning 손실 함수(finetuning_loss): 0.278053\n",
      "반복(Epoch): 9, Fine-tuning 손실 함수(finetuning_loss): 0.278197\n",
      "반복(Epoch): 10, Fine-tuning 손실 함수(finetuning_loss): 0.257313\n",
      "반복(Epoch): 11, Fine-tuning 손실 함수(finetuning_loss): 0.202036\n",
      "반복(Epoch): 12, Fine-tuning 손실 함수(finetuning_loss): 0.182953\n",
      "반복(Epoch): 13, Fine-tuning 손실 함수(finetuning_loss): 0.148870\n",
      "반복(Epoch): 14, Fine-tuning 손실 함수(finetuning_loss): 0.253974\n",
      "반복(Epoch): 15, Fine-tuning 손실 함수(finetuning_loss): 0.266112\n",
      "반복(Epoch): 16, Fine-tuning 손실 함수(finetuning_loss): 0.142853\n",
      "반복(Epoch): 17, Fine-tuning 손실 함수(finetuning_loss): 0.168350\n",
      "반복(Epoch): 18, Fine-tuning 손실 함수(finetuning_loss): 0.124167\n",
      "반복(Epoch): 19, Fine-tuning 손실 함수(finetuning_loss): 0.167056\n",
      "반복(Epoch): 20, Fine-tuning 손실 함수(finetuning_loss): 0.209862\n",
      "반복(Epoch): 21, Fine-tuning 손실 함수(finetuning_loss): 0.171208\n",
      "반복(Epoch): 22, Fine-tuning 손실 함수(finetuning_loss): 0.154197\n",
      "반복(Epoch): 23, Fine-tuning 손실 함수(finetuning_loss): 0.180782\n",
      "반복(Epoch): 24, Fine-tuning 손실 함수(finetuning_loss): 0.164480\n",
      "반복(Epoch): 25, Fine-tuning 손실 함수(finetuning_loss): 0.144154\n",
      "반복(Epoch): 26, Fine-tuning 손실 함수(finetuning_loss): 0.146405\n",
      "반복(Epoch): 27, Fine-tuning 손실 함수(finetuning_loss): 0.104606\n",
      "반복(Epoch): 28, Fine-tuning 손실 함수(finetuning_loss): 0.116411\n",
      "반복(Epoch): 29, Fine-tuning 손실 함수(finetuning_loss): 0.083642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 30, Fine-tuning 손실 함수(finetuning_loss): 0.092774\n",
      "반복(Epoch): 31, Fine-tuning 손실 함수(finetuning_loss): 0.141420\n",
      "반복(Epoch): 32, Fine-tuning 손실 함수(finetuning_loss): 0.124535\n",
      "반복(Epoch): 33, Fine-tuning 손실 함수(finetuning_loss): 0.129593\n",
      "반복(Epoch): 34, Fine-tuning 손실 함수(finetuning_loss): 0.172816\n",
      "반복(Epoch): 35, Fine-tuning 손실 함수(finetuning_loss): 0.109122\n",
      "반복(Epoch): 36, Fine-tuning 손실 함수(finetuning_loss): 0.107648\n",
      "반복(Epoch): 37, Fine-tuning 손실 함수(finetuning_loss): 0.104973\n",
      "반복(Epoch): 38, Fine-tuning 손실 함수(finetuning_loss): 0.090466\n",
      "반복(Epoch): 39, Fine-tuning 손실 함수(finetuning_loss): 0.094564\n",
      "반복(Epoch): 40, Fine-tuning 손실 함수(finetuning_loss): 0.091007\n",
      "반복(Epoch): 41, Fine-tuning 손실 함수(finetuning_loss): 0.051885\n",
      "반복(Epoch): 42, Fine-tuning 손실 함수(finetuning_loss): 0.139832\n",
      "반복(Epoch): 43, Fine-tuning 손실 함수(finetuning_loss): 0.081010\n",
      "반복(Epoch): 44, Fine-tuning 손실 함수(finetuning_loss): 0.127843\n",
      "반복(Epoch): 45, Fine-tuning 손실 함수(finetuning_loss): 0.062233\n",
      "반복(Epoch): 46, Fine-tuning 손실 함수(finetuning_loss): 0.085911\n",
      "반복(Epoch): 47, Fine-tuning 손실 함수(finetuning_loss): 0.064917\n",
      "반복(Epoch): 48, Fine-tuning 손실 함수(finetuning_loss): 0.061407\n",
      "반복(Epoch): 49, Fine-tuning 손실 함수(finetuning_loss): 0.106337\n",
      "반복(Epoch): 50, Fine-tuning 손실 함수(finetuning_loss): 0.115143\n",
      "반복(Epoch): 51, Fine-tuning 손실 함수(finetuning_loss): 0.054159\n",
      "반복(Epoch): 52, Fine-tuning 손실 함수(finetuning_loss): 0.051716\n",
      "반복(Epoch): 53, Fine-tuning 손실 함수(finetuning_loss): 0.068189\n",
      "반복(Epoch): 54, Fine-tuning 손실 함수(finetuning_loss): 0.082118\n",
      "반복(Epoch): 55, Fine-tuning 손실 함수(finetuning_loss): 0.044449\n",
      "반복(Epoch): 56, Fine-tuning 손실 함수(finetuning_loss): 0.109701\n",
      "반복(Epoch): 57, Fine-tuning 손실 함수(finetuning_loss): 0.072935\n",
      "반복(Epoch): 58, Fine-tuning 손실 함수(finetuning_loss): 0.075733\n",
      "반복(Epoch): 59, Fine-tuning 손실 함수(finetuning_loss): 0.043971\n",
      "반복(Epoch): 60, Fine-tuning 손실 함수(finetuning_loss): 0.051374\n",
      "반복(Epoch): 61, Fine-tuning 손실 함수(finetuning_loss): 0.061025\n",
      "반복(Epoch): 62, Fine-tuning 손실 함수(finetuning_loss): 0.084910\n",
      "반복(Epoch): 63, Fine-tuning 손실 함수(finetuning_loss): 0.060630\n",
      "반복(Epoch): 64, Fine-tuning 손실 함수(finetuning_loss): 0.041317\n",
      "반복(Epoch): 65, Fine-tuning 손실 함수(finetuning_loss): 0.056398\n",
      "반복(Epoch): 66, Fine-tuning 손실 함수(finetuning_loss): 0.093380\n",
      "반복(Epoch): 67, Fine-tuning 손실 함수(finetuning_loss): 0.082470\n",
      "반복(Epoch): 68, Fine-tuning 손실 함수(finetuning_loss): 0.089068\n",
      "반복(Epoch): 69, Fine-tuning 손실 함수(finetuning_loss): 0.082338\n",
      "반복(Epoch): 70, Fine-tuning 손실 함수(finetuning_loss): 0.074801\n",
      "반복(Epoch): 71, Fine-tuning 손실 함수(finetuning_loss): 0.040922\n",
      "반복(Epoch): 72, Fine-tuning 손실 함수(finetuning_loss): 0.059720\n",
      "반복(Epoch): 73, Fine-tuning 손실 함수(finetuning_loss): 0.060917\n",
      "반복(Epoch): 74, Fine-tuning 손실 함수(finetuning_loss): 0.041911\n",
      "반복(Epoch): 75, Fine-tuning 손실 함수(finetuning_loss): 0.044395\n",
      "반복(Epoch): 76, Fine-tuning 손실 함수(finetuning_loss): 0.055489\n",
      "반복(Epoch): 77, Fine-tuning 손실 함수(finetuning_loss): 0.061628\n",
      "반복(Epoch): 78, Fine-tuning 손실 함수(finetuning_loss): 0.021143\n",
      "반복(Epoch): 79, Fine-tuning 손실 함수(finetuning_loss): 0.054629\n",
      "반복(Epoch): 80, Fine-tuning 손실 함수(finetuning_loss): 0.048292\n",
      "반복(Epoch): 81, Fine-tuning 손실 함수(finetuning_loss): 0.052972\n",
      "반복(Epoch): 82, Fine-tuning 손실 함수(finetuning_loss): 0.044049\n",
      "반복(Epoch): 83, Fine-tuning 손실 함수(finetuning_loss): 0.036559\n",
      "반복(Epoch): 84, Fine-tuning 손실 함수(finetuning_loss): 0.040890\n",
      "반복(Epoch): 85, Fine-tuning 손실 함수(finetuning_loss): 0.054759\n",
      "반복(Epoch): 86, Fine-tuning 손실 함수(finetuning_loss): 0.040176\n",
      "반복(Epoch): 87, Fine-tuning 손실 함수(finetuning_loss): 0.037599\n",
      "반복(Epoch): 88, Fine-tuning 손실 함수(finetuning_loss): 0.034579\n",
      "반복(Epoch): 89, Fine-tuning 손실 함수(finetuning_loss): 0.035124\n",
      "반복(Epoch): 90, Fine-tuning 손실 함수(finetuning_loss): 0.043844\n",
      "반복(Epoch): 91, Fine-tuning 손실 함수(finetuning_loss): 0.037976\n",
      "반복(Epoch): 92, Fine-tuning 손실 함수(finetuning_loss): 0.020486\n",
      "반복(Epoch): 93, Fine-tuning 손실 함수(finetuning_loss): 0.043242\n",
      "반복(Epoch): 94, Fine-tuning 손실 함수(finetuning_loss): 0.066530\n",
      "반복(Epoch): 95, Fine-tuning 손실 함수(finetuning_loss): 0.026842\n",
      "반복(Epoch): 96, Fine-tuning 손실 함수(finetuning_loss): 0.038515\n",
      "반복(Epoch): 97, Fine-tuning 손실 함수(finetuning_loss): 0.061584\n",
      "반복(Epoch): 98, Fine-tuning 손실 함수(finetuning_loss): 0.079248\n",
      "반복(Epoch): 99, Fine-tuning 손실 함수(finetuning_loss): 0.027202\n",
      "반복(Epoch): 100, Fine-tuning 손실 함수(finetuning_loss): 0.031699\n",
      "반복(Epoch): 101, Fine-tuning 손실 함수(finetuning_loss): 0.036209\n",
      "반복(Epoch): 102, Fine-tuning 손실 함수(finetuning_loss): 0.063161\n",
      "반복(Epoch): 103, Fine-tuning 손실 함수(finetuning_loss): 0.044356\n",
      "반복(Epoch): 104, Fine-tuning 손실 함수(finetuning_loss): 0.045489\n",
      "반복(Epoch): 105, Fine-tuning 손실 함수(finetuning_loss): 0.034562\n",
      "반복(Epoch): 106, Fine-tuning 손실 함수(finetuning_loss): 0.056989\n",
      "반복(Epoch): 107, Fine-tuning 손실 함수(finetuning_loss): 0.029342\n",
      "반복(Epoch): 108, Fine-tuning 손실 함수(finetuning_loss): 0.044789\n",
      "반복(Epoch): 109, Fine-tuning 손실 함수(finetuning_loss): 0.056611\n",
      "반복(Epoch): 110, Fine-tuning 손실 함수(finetuning_loss): 0.034365\n",
      "반복(Epoch): 111, Fine-tuning 손실 함수(finetuning_loss): 0.023801\n",
      "반복(Epoch): 112, Fine-tuning 손실 함수(finetuning_loss): 0.038071\n",
      "반복(Epoch): 113, Fine-tuning 손실 함수(finetuning_loss): 0.022937\n",
      "반복(Epoch): 114, Fine-tuning 손실 함수(finetuning_loss): 0.014439\n",
      "반복(Epoch): 115, Fine-tuning 손실 함수(finetuning_loss): 0.024162\n",
      "반복(Epoch): 116, Fine-tuning 손실 함수(finetuning_loss): 0.022765\n",
      "반복(Epoch): 117, Fine-tuning 손실 함수(finetuning_loss): 0.019403\n",
      "반복(Epoch): 118, Fine-tuning 손실 함수(finetuning_loss): 0.022163\n",
      "반복(Epoch): 119, Fine-tuning 손실 함수(finetuning_loss): 0.019317\n",
      "반복(Epoch): 120, Fine-tuning 손실 함수(finetuning_loss): 0.028743\n",
      "반복(Epoch): 121, Fine-tuning 손실 함수(finetuning_loss): 0.023112\n",
      "반복(Epoch): 122, Fine-tuning 손실 함수(finetuning_loss): 0.023364\n",
      "반복(Epoch): 123, Fine-tuning 손실 함수(finetuning_loss): 0.021434\n",
      "반복(Epoch): 124, Fine-tuning 손실 함수(finetuning_loss): 0.025716\n",
      "반복(Epoch): 125, Fine-tuning 손실 함수(finetuning_loss): 0.015578\n",
      "반복(Epoch): 126, Fine-tuning 손실 함수(finetuning_loss): 0.024158\n",
      "반복(Epoch): 127, Fine-tuning 손실 함수(finetuning_loss): 0.039893\n",
      "반복(Epoch): 128, Fine-tuning 손실 함수(finetuning_loss): 0.016734\n",
      "반복(Epoch): 129, Fine-tuning 손실 함수(finetuning_loss): 0.025734\n",
      "반복(Epoch): 130, Fine-tuning 손실 함수(finetuning_loss): 0.030781\n",
      "반복(Epoch): 131, Fine-tuning 손실 함수(finetuning_loss): 0.022036\n",
      "반복(Epoch): 132, Fine-tuning 손실 함수(finetuning_loss): 0.014363\n",
      "반복(Epoch): 133, Fine-tuning 손실 함수(finetuning_loss): 0.032314\n",
      "반복(Epoch): 134, Fine-tuning 손실 함수(finetuning_loss): 0.016591\n",
      "반복(Epoch): 135, Fine-tuning 손실 함수(finetuning_loss): 0.025968\n",
      "반복(Epoch): 136, Fine-tuning 손실 함수(finetuning_loss): 0.023525\n",
      "반복(Epoch): 137, Fine-tuning 손실 함수(finetuning_loss): 0.018939\n",
      "반복(Epoch): 138, Fine-tuning 손실 함수(finetuning_loss): 0.015054\n",
      "반복(Epoch): 139, Fine-tuning 손실 함수(finetuning_loss): 0.022465\n",
      "반복(Epoch): 140, Fine-tuning 손실 함수(finetuning_loss): 0.048347\n",
      "반복(Epoch): 141, Fine-tuning 손실 함수(finetuning_loss): 0.016087\n",
      "반복(Epoch): 142, Fine-tuning 손실 함수(finetuning_loss): 0.027032\n",
      "반복(Epoch): 143, Fine-tuning 손실 함수(finetuning_loss): 0.021879\n",
      "반복(Epoch): 144, Fine-tuning 손실 함수(finetuning_loss): 0.025817\n",
      "반복(Epoch): 145, Fine-tuning 손실 함수(finetuning_loss): 0.025342\n",
      "반복(Epoch): 146, Fine-tuning 손실 함수(finetuning_loss): 0.025462\n",
      "반복(Epoch): 147, Fine-tuning 손실 함수(finetuning_loss): 0.011415\n",
      "반복(Epoch): 148, Fine-tuning 손실 함수(finetuning_loss): 0.022998\n",
      "반복(Epoch): 149, Fine-tuning 손실 함수(finetuning_loss): 0.039554\n",
      "반복(Epoch): 150, Fine-tuning 손실 함수(finetuning_loss): 0.009893\n",
      "반복(Epoch): 151, Fine-tuning 손실 함수(finetuning_loss): 0.014772\n",
      "반복(Epoch): 152, Fine-tuning 손실 함수(finetuning_loss): 0.023529\n",
      "반복(Epoch): 153, Fine-tuning 손실 함수(finetuning_loss): 0.008726\n",
      "반복(Epoch): 154, Fine-tuning 손실 함수(finetuning_loss): 0.020516\n",
      "반복(Epoch): 155, Fine-tuning 손실 함수(finetuning_loss): 0.010202\n",
      "반복(Epoch): 156, Fine-tuning 손실 함수(finetuning_loss): 0.010465\n",
      "반복(Epoch): 157, Fine-tuning 손실 함수(finetuning_loss): 0.023156\n",
      "반복(Epoch): 158, Fine-tuning 손실 함수(finetuning_loss): 0.012222\n",
      "반복(Epoch): 159, Fine-tuning 손실 함수(finetuning_loss): 0.016898\n",
      "반복(Epoch): 160, Fine-tuning 손실 함수(finetuning_loss): 0.018009\n",
      "반복(Epoch): 161, Fine-tuning 손실 함수(finetuning_loss): 0.018307\n",
      "반복(Epoch): 162, Fine-tuning 손실 함수(finetuning_loss): 0.012392\n",
      "반복(Epoch): 163, Fine-tuning 손실 함수(finetuning_loss): 0.013908\n",
      "반복(Epoch): 164, Fine-tuning 손실 함수(finetuning_loss): 0.061190\n",
      "반복(Epoch): 165, Fine-tuning 손실 함수(finetuning_loss): 0.037238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(Epoch): 166, Fine-tuning 손실 함수(finetuning_loss): 0.007615\n",
      "반복(Epoch): 167, Fine-tuning 손실 함수(finetuning_loss): 0.015103\n",
      "반복(Epoch): 168, Fine-tuning 손실 함수(finetuning_loss): 0.014852\n",
      "반복(Epoch): 169, Fine-tuning 손실 함수(finetuning_loss): 0.030615\n",
      "반복(Epoch): 170, Fine-tuning 손실 함수(finetuning_loss): 0.012748\n",
      "반복(Epoch): 171, Fine-tuning 손실 함수(finetuning_loss): 0.029258\n",
      "반복(Epoch): 172, Fine-tuning 손실 함수(finetuning_loss): 0.017449\n",
      "반복(Epoch): 173, Fine-tuning 손실 함수(finetuning_loss): 0.023598\n",
      "반복(Epoch): 174, Fine-tuning 손실 함수(finetuning_loss): 0.011592\n",
      "반복(Epoch): 175, Fine-tuning 손실 함수(finetuning_loss): 0.011586\n",
      "반복(Epoch): 176, Fine-tuning 손실 함수(finetuning_loss): 0.011039\n",
      "반복(Epoch): 177, Fine-tuning 손실 함수(finetuning_loss): 0.010931\n",
      "반복(Epoch): 178, Fine-tuning 손실 함수(finetuning_loss): 0.018721\n",
      "반복(Epoch): 179, Fine-tuning 손실 함수(finetuning_loss): 0.012446\n",
      "반복(Epoch): 180, Fine-tuning 손실 함수(finetuning_loss): 0.009419\n",
      "반복(Epoch): 181, Fine-tuning 손실 함수(finetuning_loss): 0.011065\n",
      "반복(Epoch): 182, Fine-tuning 손실 함수(finetuning_loss): 0.010548\n",
      "반복(Epoch): 183, Fine-tuning 손실 함수(finetuning_loss): 0.009482\n",
      "반복(Epoch): 184, Fine-tuning 손실 함수(finetuning_loss): 0.024555\n",
      "반복(Epoch): 185, Fine-tuning 손실 함수(finetuning_loss): 0.015367\n",
      "반복(Epoch): 186, Fine-tuning 손실 함수(finetuning_loss): 0.009899\n",
      "반복(Epoch): 187, Fine-tuning 손실 함수(finetuning_loss): 0.013351\n",
      "반복(Epoch): 188, Fine-tuning 손실 함수(finetuning_loss): 0.032731\n",
      "반복(Epoch): 189, Fine-tuning 손실 함수(finetuning_loss): 0.011253\n",
      "반복(Epoch): 190, Fine-tuning 손실 함수(finetuning_loss): 0.018958\n",
      "반복(Epoch): 191, Fine-tuning 손실 함수(finetuning_loss): 0.008593\n",
      "반복(Epoch): 192, Fine-tuning 손실 함수(finetuning_loss): 0.010170\n",
      "반복(Epoch): 193, Fine-tuning 손실 함수(finetuning_loss): 0.016347\n",
      "반복(Epoch): 194, Fine-tuning 손실 함수(finetuning_loss): 0.015007\n",
      "반복(Epoch): 195, Fine-tuning 손실 함수(finetuning_loss): 0.010463\n",
      "반복(Epoch): 196, Fine-tuning 손실 함수(finetuning_loss): 0.011275\n",
      "반복(Epoch): 197, Fine-tuning 손실 함수(finetuning_loss): 0.015278\n",
      "반복(Epoch): 198, Fine-tuning 손실 함수(finetuning_loss): 0.007476\n",
      "반복(Epoch): 199, Fine-tuning 손실 함수(finetuning_loss): 0.016753\n",
      "반복(Epoch): 200, Fine-tuning 손실 함수(finetuning_loss): 0.006411\n",
      "Step 2 : MNIST 데이터 분류를 위한 오토인코더+Softmax 분류기 최적화 완료(Fine-Tuning)\n",
      "오토인코더+Sotfmax 분류기 모델의 정확도\n",
      "정확도(오토인코더+Softmax 분류기): 0.962300\n"
     ]
    }
   ],
   "source": [
    "# MNIST 숫자 분류를 위한 Autoencoder+Softmax 분류기 예제 \n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "print(\"getting mnist data..\", end =\"\")\n",
    "mnist = input_data.read_data_sets(\"D:/mnist/data/\", one_hot=True)\n",
    "print(\"done!\")\n",
    "\n",
    "learning_rate_RMSProp = 0.02\n",
    "learning_rate_GradientDescent = 0.5\n",
    "num_epochs = 100\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "input_size = 784\n",
    "hidden1_size = 128\n",
    "hidden2_size = 64\n",
    "\n",
    "x = tf.placeholder(\"float\", [None, input_size])\n",
    "y = tf.placeholder(tf.float32, [None, 10])\n",
    "\n",
    "# autoencoder 구조 정의\n",
    "def build_autoencoder(x):\n",
    "    # 인코딩 784 -> 128 -> 64\n",
    "    Wh_1 = tf.Variable(tf.random_normal([input_size,hidden1_size]))\n",
    "    bh_1 = tf.Variable(tf.random_normal([hidden1_size]))\n",
    "    H1_output = tf.nn.sigmoid(tf.matmul(x, Wh_1)+bh_1)\n",
    "    Wh_2 = tf.Variable(tf.random_normal([hidden1_size,hidden2_size]))\n",
    "    bh_2 = tf.Variable(tf.random_normal([hidden2_size]))\n",
    "    H2_output = tf.nn.sigmoid(tf.matmul(H1_output,Wh_2)+bh_2)\n",
    "    # 디코딩 64 -> 128 -> 784\n",
    "    Wh_3 = tf.Variable(tf.random_normal([hidden2_size,hidden1_size]))\n",
    "    bh_3 = tf.Variable(tf.random_normal([hidden1_size]))\n",
    "    H3_output = tf.nn.sigmoid(tf.matmul(H2_output,Wh_3)+bh_3)\n",
    "    Wo = tf.Variable(tf.random_normal([hidden1_size, input_size]))\n",
    "    bo = tf.Variable(tf.random_normal([input_size]))\n",
    "    X_reconstructed = tf.nn.sigmoid(tf.matmul(H3_output,Wo)+bo)\n",
    "    return X_reconstructed, H2_output\n",
    "\n",
    "def build_softmax_classifier(x):\n",
    "    W_softmax = tf.Variable(tf.zeros([hidden2_size,10])) # 입력값으로 오토인코딩 중간값(64)을 받는다.\n",
    "    b_softmax = tf.Variable(tf.zeros([10]))\n",
    "    y_pred = tf.nn.softmax(tf.matmul(x, W_softmax) + b_softmax)\n",
    "    \n",
    "    return y_pred\n",
    "#분류기 선언 (오토인코더, 소맥분류기)\n",
    "y_pred, extracted_features = build_autoencoder(x)\n",
    "y_true = x\n",
    "y_pred_softmax = build_softmax_classifier(extracted_features)\n",
    "\n",
    "# 1. Pre-Training : MNIST 데이터 재구축을 목적으로하는 손실함수와 옵티마이저를 정의합니다.\n",
    "pretraining_loss = tf.reduce_mean(tf.pow(y_true-y_pred, 2)) # MSE\n",
    "pretraining_train_step = tf.train.RMSPropOptimizer(learning_rate_RMSProp).minimize(pretraining_loss)\n",
    "# 2. Fine-Tuning :  MNIST 데이터 분류를 목적으로하는 손실함수와 옵티마이저를 정의합니다.\n",
    "finetuning_loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_pred_softmax),reduction_indices=[1])) # cross-entropy loss 함수\n",
    "finetuning_train_step = tf.train.GradientDescentOptimizer(learning_rate_GradientDescent).minimize(finetuning_loss)\n",
    "\n",
    "print(\"======== Session start! ========\")\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4 # GPU메모리 적용 % 설정\n",
    "\n",
    "with tf.Session(config=config) as sess :\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    total_batch = int(mnist.train.num_examples/batch_size)\n",
    "    \n",
    "    # 데이터 재구축을 위한 오토인코더 최적화\n",
    "    for epoch in range(num_epochs):\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, pretraining_loss_print = sess.run([pretraining_train_step, pretraining_loss], feed_dict={x:batch_xs})\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"반복(Epoch): %d, Pre-Training 손실 함수(pretraining_loss): %f\" % ((epoch+1), pretraining_loss_print))\n",
    "    print(\"Step 1: MNIST 데이터 재구축을 위한 오토인코더 최적화 완료(Pre-Training)-----\")\n",
    "    \n",
    "    # 오토인코더+Softmax 분류기 최적화(Fine-Tuning)\n",
    "    for epoch in range(num_epochs+100):\n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, finetuning_loss_print = sess.run([finetuning_train_step, finetuning_loss], feed_dict={x:batch_xs, y:batch_ys})\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"반복(Epoch): %d, Fine-tuning 손실 함수(finetuning_loss): %f\" % ((epoch+1), finetuning_loss_print))\n",
    "    print(\"Step 2 : MNIST 데이터 분류를 위한 오토인코더+Softmax 분류기 최적화 완료(Fine-Tuning)\")\n",
    "    \n",
    "    print(\"오토인코더+Sotfmax 분류기 모델의 정확도\")\n",
    "    correct_prediction = tf.equal(tf.argmax(y,1),tf.argmax(y_pred_softmax,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    print(\"정확도(오토인코더+Softmax 분류기): %f\" % sess.run(accuracy, feed_dict={x: mnist.test.images, y: mnist.test.labels}))\n",
    "    # 정확도 : 약 96%                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting mnist data..Extracting D:/mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting D:/mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting D:/mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting D:/mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "done!\n",
      "반복(Epoch): 1, 손실함수(Loss): 339.360990\n",
      "반복(Epoch): 2, 손실함수(Loss): 70.817797\n",
      "반복(Epoch): 3, 손실함수(Loss): 45.682189\n",
      "반복(Epoch): 4, 손실함수(Loss): 33.594645\n",
      "반복(Epoch): 5, 손실함수(Loss): 26.050459\n",
      "반복(Epoch): 6, 손실함수(Loss): 20.927511\n",
      "반복(Epoch): 7, 손실함수(Loss): 17.077748\n",
      "반복(Epoch): 8, 손실함수(Loss): 14.123513\n",
      "반복(Epoch): 9, 손실함수(Loss): 11.684944\n",
      "반복(Epoch): 10, 손실함수(Loss): 9.768534\n",
      "반복(Epoch): 11, 손실함수(Loss): 8.292251\n",
      "반복(Epoch): 12, 손실함수(Loss): 6.934254\n",
      "반복(Epoch): 13, 손실함수(Loss): 5.873875\n",
      "반복(Epoch): 14, 손실함수(Loss): 5.122012\n",
      "반복(Epoch): 15, 손실함수(Loss): 4.194094\n",
      "반복(Epoch): 16, 손실함수(Loss): 3.560020\n",
      "반복(Epoch): 17, 손실함수(Loss): 2.955774\n",
      "반복(Epoch): 18, 손실함수(Loss): 2.454643\n",
      "반복(Epoch): 19, 손실함수(Loss): 1.917150\n",
      "반복(Epoch): 20, 손실함수(Loss): 1.628822\n",
      "반복(Epoch): 21, 손실함수(Loss): 1.417051\n",
      "반복(Epoch): 22, 손실함수(Loss): 1.142807\n",
      "반복(Epoch): 23, 손실함수(Loss): 0.885293\n",
      "반복(Epoch): 24, 손실함수(Loss): 0.699958\n",
      "반복(Epoch): 25, 손실함수(Loss): 0.588272\n",
      "반복(Epoch): 26, 손실함수(Loss): 0.467618\n",
      "반복(Epoch): 27, 손실함수(Loss): 0.409771\n",
      "반복(Epoch): 28, 손실함수(Loss): 0.416350\n",
      "반복(Epoch): 29, 손실함수(Loss): 0.266140\n",
      "반복(Epoch): 30, 손실함수(Loss): 0.227277\n",
      "정확도(Accuracy): 0.942800\n"
     ]
    }
   ],
   "source": [
    "# ANN 기본\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "print(\"getting mnist data..\", end =\"\")\n",
    "mnist = input_data.read_data_sets(\"D:/mnist/data/\", one_hot=True)\n",
    "print(\"done!\")\n",
    "\n",
    "learning_rate = 0.001\n",
    "num_epochs = 30\n",
    "batch_size = 256\n",
    "display_step = 1\n",
    "input_size = 784\n",
    "hidden1_size = 256\n",
    "hidden2_size = 256\n",
    "output_size = 10\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "y = tf.placeholder(tf.float32, shape=[None, output_size])\n",
    "\n",
    "def build_ANN(x):\n",
    "    W1 = tf.Variable(tf.random_normal(shape=[input_size, hidden1_size]))\n",
    "    b1 = tf.Variable(tf.random_normal(shape=[hidden1_size]))\n",
    "    H1_output = tf.nn.relu(tf.matmul(x,W1) + b1)\n",
    "    W2 = tf.Variable(tf.random_normal(shape=[hidden1_size, hidden2_size]))\n",
    "    b2 = tf.Variable(tf.random_normal(shape=[hidden2_size]))\n",
    "    H2_output = tf.nn.relu(tf.matmul(H1_output,W2)+b2)\n",
    "    W_output = tf.Variable(tf.random_normal(shape=[hidden2_size, output_size]))\n",
    "    b_output = tf.Variable(tf.random_normal(shape=[output_size]))\n",
    "    \n",
    "    logits = tf.matmul(H2_output, W_output) + b_output\n",
    "    \n",
    "    return logits\n",
    "\n",
    "predicted_value = build_ANN(x)\n",
    "\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=predicted_value,labels=y))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(loss)\n",
    "\n",
    "print(\"======== Session start! ========\")\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4 # GPU메모리 적용 % 설정\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        average_loss = 0.\n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, current_loss = sess.run([train_step, loss], feed_dict={x:batch_x,y:batch_y})\n",
    "            \n",
    "            average_loss += current_loss/total_batch\n",
    "            \n",
    "        if epoch % display_step == 0:\n",
    "            print(\"반복(Epoch): %d, 손실함수(Loss): %f\"%((epoch+1),average_loss))\n",
    "                  \n",
    "    correct_prediction = tf.equal(tf.argmax(predicted_value, 1), tf.argmax(y,1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"정확도(Accuracy): %f\" %(accuracy.eval(feed_dict={x:mnist.test.images, y:mnist.test.labels})))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\creal\\Anaconda3\\lib\\site-packages\\matplotlib\\figure.py:403: UserWarning: matplotlib is currently using a non-GUI backend, so cannot show the figure\n",
      "  \"matplotlib is currently using a non-GUI backend, \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJ8AAAEbCAYAAAB0lCUYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x23590bced30>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 141,
       "width": 591
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Autoencoder 오토인코더 reconstruction\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "print(\"getting mnist data..\", end =\"\")\n",
    "mnist = input_data.read_data_sets(\"D:/mnist/data/\", one_hot=True)\n",
    "print(\"done!\")\n",
    "\n",
    "# 학습에 필요한 설정값 정의!\n",
    "\n",
    "learning_rate = 0.02\n",
    "training_epochs = 50\n",
    "batch_size = 512\n",
    "display_step = 1      # 손실함수 출력 주기\n",
    "examples_to_show = 10 # 보여줄 이미지 개수\n",
    "input_size = 784      #28*28\n",
    "hidden1_size = 256\n",
    "hidden2_size = 128\n",
    "\n",
    "# 오토인코더는 비지도학습 == Y가 필요엄슴\n",
    "x = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "\n",
    "#구조 정의\n",
    "def build_autoencoder(x):\n",
    "    W1 = tf.Variable(tf.random_normal(shape=[input_size, hidden1_size]))\n",
    "    b1 = tf.Variable(tf.random_normal(shape=[hidden1_size]))\n",
    "    H1_output = tf.nn.sigmoid(tf.matmul(x,W1) + b1)\n",
    "    W2 = tf.Variable(tf.random_normal(shape=[hidden1_size, hidden2_size]))\n",
    "    b2 = tf.Variable(tf.random_normal(shape=[hidden2_size]))\n",
    "    H2_output = tf.nn.sigmoid(tf.matmul(H1_output,W2) + b2)\n",
    "    \n",
    "    # 디코딩!\n",
    "    W3 = tf.Variable(tf.random_normal(shape=[hidden2_size, hidden1_size]))\n",
    "    b3 = tf.Variable(tf.random_normal(shape=[hidden1_size]))\n",
    "    H3_output = tf.nn.sigmoid(tf.matmul(H2_output,W3) + b3)\n",
    "    W4 = tf.Variable(tf.random_normal(shape=[hidden1_size, input_size]))\n",
    "    b4 = tf.Variable(tf.random_normal(shape=[input_size]))\n",
    "    reconstructed_x = tf.nn.sigmoid(tf.matmul(H3_output,W4) + b4)\n",
    "    \n",
    "    return reconstructed_x\n",
    "\n",
    "y_pred = build_autoencoder(x)\n",
    "# 타겟데이터는 인풋데이터와 같다.\n",
    "y_true = x\n",
    "\n",
    "loss = tf.reduce_mean(tf.pow(y_true - y_pred, 2)) # MSE임\n",
    "train_step = tf.train.RMSPropOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "print(\"======== Session start! ========\")\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "# config.gpu_options.per_process_gpu_memory_fraction = 0.4 # GPU메모리 적용 % 설정\n",
    "\n",
    "with tf.Session(config=config) as sess:\n",
    "    # 변수 초기값 할당\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for epoch in range(training_epochs):\n",
    "        \n",
    "        total_batch = int(mnist.train.num_examples/batch_size)\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "            _, current_loss = sess.run([train_step, loss], feed_dict={x:batch_xs})\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"반복(Epoch): %d, 손실 함수(Loss): %f\" % ((epoch+1), current_loss))\n",
    "    \n",
    "    reconstructed_result = sess.run(y_pred, feed_dict={x:mnist.test.images[:examples_to_show]})\n",
    "    f, a = plt.subplots(2,10, figsize=(10,2))\n",
    "    for i in range(examples_to_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.test.images[i],(28,28)))\n",
    "        a[1][i].imshow(np.reshape(reconstructed_result[i],(28,28)))\n",
    "    f.savefig('reconstructed_mnist_image.png') # reconstruction 결과를 png로 저장합니다.\n",
    "    clear_output()\n",
    "    f.show()\n",
    "    plt.draw()\n",
    "#     plt.waitforbuttonpress()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "getting mnist data..Extracting D:/mnist/data/train-images-idx3-ubyte.gz\n",
      "Extracting D:/mnist/data/train-labels-idx1-ubyte.gz\n",
      "Extracting D:/mnist/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting D:/mnist/data/t10k-labels-idx1-ubyte.gz\n",
      "done!\n",
      "WARNING:tensorflow:From <ipython-input-7-42d01363b493>:20: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n",
      "======== Session start! ========\n",
      "epoch :  999 --- 352 ---  --- 825 --- \n",
      "정확도(Accuracy): 0.919100\n"
     ]
    }
   ],
   "source": [
    "# 기초...softmax regression\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "\n",
    "print(\"getting mnist data..\", end =\"\")\n",
    "mnist = input_data.read_data_sets(\"D:/mnist/data/\", one_hot=True)\n",
    "print(\"done!\")\n",
    "\n",
    "# with tf.device('/cpu:0'):\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784])\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "\n",
    "W = tf.Variable(tf.zeros(shape=[784, 10]))\n",
    "b = tf.Variable(tf.zeros(shape=[10]))\n",
    "\n",
    "logits = tf.matmul(x, W) +b\n",
    "y_pred = tf.nn.softmax(logits)\n",
    "\n",
    "# cross-entropy 손실 함수와 옵티마이저를 정의합니다.\n",
    "# loss = tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_pred), reduction_indices=[1]))\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=y))  # tf.nn.softmax_cross_entropy_with_logits API를 이용한 구현\n",
    "train_step = tf.train.GradientDescentOptimizer(0.5).minimize(loss)\n",
    "\n",
    "print(\"======== Session start! ========\")\n",
    "\n",
    "config = tf.ConfigProto(log_device_placement=True)\n",
    "# config.gpu_options.allow_growth = True\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4 # GPU메모리 적용 % 설정\n",
    "\n",
    "sess = tf.Session(config=config) # 자동 디바이스 로깅 == GPU알아서 찾아가지고 적용시킴\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "for i in range(1000):\n",
    "    print(\"epoch : \", i , end=\" --- \\r\")\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(100)\n",
    "    sess.run(train_step, feed_dict={x: batch_xs, y: batch_ys})\n",
    "    \n",
    "print(\"\")\n",
    "correct_prediction = tf.equal(tf.argmax(y_pred,1), tf.argmax(y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"정확도(Accuracy): %f\"%sess.run(accuracy, feed_dict={x:mnist.test.images, y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
